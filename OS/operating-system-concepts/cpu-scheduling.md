> **CPU 스케줄링(scheduling)**

→ ***다중 프로그램 운영체제의 기본으로, 운영체제는 CPU를 프로세스 간에 교환함으로써 컴퓨터를 보다 생산적으로 만든다.***

- 이번 단원에서는 기본적인 스케줄링 개념 및 여러 스케줄링 알고리즘을 학습한다!

---

## 1. 기본 개념

→ ***코어가 하나인 시스템에서는 한순간에 오직 하나의 프로세스만이 실행될 수 있다.***

- **나머지 프로세스는 CPU의 코어가 가용 상태가 되어 다시 스케줄 될 수 있을 때까지 기다려야 한다.**

</br>

> **다중 프로그래밍의 목적**

→ ***CPU 이용률을 최대화하기 위해, 항상 실행 중인 프로세스를 가지게 하는 것이다.***

- 하나의 프로세스는 어떤 입출력 요청이 완료되기를 기다려야만 실행된다.
    - 단순한 컴퓨터 시스템에서 **CPU는 놀고 있게 되고, 대기 시간은 낭비되며 유용한 작업도 수행하지 못한다.**

</br>

→ **다중 프로그래밍에서는 이러한 시간을 생산적으로 활용하려고 시도한다.**

- 다수의 프로세스를 메모리 내에 유지하고, 어떤 프로세스가 대기해야 할 경우 **운영체제는 CPU를 그 프로세스로부터 회수**한다.
    - 그 후, **다른 프로세스에 할당**한다.

</br>

> **스케줄링은 운영체제의 기본적인 기능이며, 운영체제 설계의 핵심이 된다.**

</br>

### CPU-I/O 버스트 사이클

→ ***CPU 스케줄링의 성공은 프로세스들의 다음과 같은 성질에 의해 좌우된다.***

- 프로세스 실행은 **CPU 실행과 I/O 대기의 사이클**로 구성된다.
    - 프로세스들은 이들 두 상태 사이를 교대로 왔다 갔다 한다.

</br>

- 프로세스 실행은 **CPU 버스트**로 시작된다.
    - 뒤이어 **I/O 버스트**가 발생하고, 또 다른 CPU 버스트가 발생하며, 이어서 또 다른 I/O 버스트 등등으로 진행된다.
    - 마지막 CPU 버스트는 실행을 종료하기 위한 시스템 요청과 함께 끝난다.

<img width="263" alt="image" src="https://user-images.githubusercontent.com/106216912/211205048-fababfcf-e7d2-41b8-950f-6cda0d23e346.png">

</br>

> **CPU 버스트들의 지속 시간은 컴퓨터 마다 변화가 크지만, 다음 그림과 유사한 빈도수 곡선을 갖는 경향이 있다.**

<img width="476" alt="image" src="https://user-images.githubusercontent.com/106216912/211205081-16f56b39-8c8d-41d2-90c4-f19852ebf073.png">

- 짧은 CPU 버스트가 많고, 긴 CPU 버스트는 적다.
- 입출력 중심의 프로그램은 전형적으로 짧은 CPU 버스트를 많이 가질 것이고, CPU 지향 프로그램은 다수의 긴 CPU 버스트를 가질 수 있다.

</br>

### CPU 스케줄러

→ ***CPU가 쉬는 상태가 될 때마다, 운영체제는 준비 큐에 있는 프로세스 중에서 하나를 선택해 실행해야 한다.***

- 선택 절차는 **CPU 스케줄러에 의해 수행**된다.
- 스케줄러는 **실행 준비가 되어 있는 메모리 내의 프로세스 중에서 선택해서, 이들 중 하나에게 CPU를 할당**한다.

</br>

> **준비 큐는 반드시 선입선출(FIFO) 방식의 큐는 아니다!**

- 준비 큐는 선입 선출 큐, 우선순위 큐, 트리, 연결 리스트 등으로 구현할 수 있다.
- 큐에 있는 레코드들은 일반적으로 프로세스들의 **프로세스 제어 블록(PCB)** 들이다.

</br>

### 선점 및 비선점 스케줄링

→ ***CPU 스케줄링 결정은 다음의 네 가지 상황에서 발생할 수 있다.***

<img width="488" alt="image" src="https://user-images.githubusercontent.com/106216912/211205153-78eb929a-56da-46fb-ad55-3240868838b0.png">

1. **한 프로세스가 실행 상태에서 대기 상태로 전환될 때**
2. **프로세스가 실행 상태에서 준비 완료 상태로 전환될 때**
3. **프로세스가 대기 상태에서 준비 완료 상태로 전환될 때**
4. **프로세스가 종료할 때**

</br>

→ 상황 1과 4의 경우에는 **스케줄링 면에서 선택의 여지가 없고, 실행을 위해 새로운 프로세스가 반드시 선택되어야 한다.**

- 하지만, 상황 2와 3에서는 선택의 여지가 있다.

</br>

> **상황 1과 4에서만 스케줄링이 발생할 경우, 이러한 스케줄링 방법을 비선점 또는 협조적이라고 한다.**

→ 그렇지 않은 경우는, **선점**이라고 한다.

</br>

- **비선점 스케줄링**
    - CPU가 한 프로세스에 할당되면 프로세스가 종료하든지, 또는 대기 상태로 전환해 CPU를 방출할 때까지 점유한다.

</br>

- **선점 스케줄링**
    - 거의 모든 최신 운영체제들은 선점 스케줄링 알고리즘을 사용한다.
    - 데이터가 다수의 프로세스에 의해 공유될 때, 경쟁 조건을 초래할 수 있다.
    - 운영체제 커널 설계에 영향을 준다.

</br>

> **운영체제 커널은 선점, 또는 비선점 방식으로 설계될 수 있다.**

- **비선점형 커널**
    - 문맥 교환을 하기 전에, 시스템 콜이 완료되거나 입출력 완료를 기다리며 프로세스가 봉쇄되기를 기다린다.
    - 커널이 프로세스를 선점하지 않기 때문에, 커널 구조가 단순하다.
    - 주어진 시간 안에 태스크의 실행이 완료되어야 하는 실시간 컴퓨팅에서는 좋은 모델이 아니다.

</br>

- **선점형 커널**
    - 공유 커널 데이터 구조에 액세스 할 때 경쟁 조건을 방지하기 위해, mutex 락 같은 기법이 필요하다.

</br>

→ **인터럽트는 언제든지 일어날 수 있고, 항상 무시될 수는 없기 때문에 반드시 동시 사용으로부터 보호되어야 한다!**

</br>

### 디스패처

→ ***CPU 스케줄링 기능에 포함된 또 하나의 요소는 디스패처(dispatcher)이다.***

- **디스패처는 CPU 코어의 제어를 CPU 스케줄러가 선택한 프로세스에 주는 모듈**로, 다음과 같은 작업을 포함한다.
    - 한 프로세스에서 다른 프로세스로 문맥을 교환하는 일
    - 사용자 모드로 전환하는 일
    - 프로그램을 다시 시작하기 위해 사용자 프로그램의 적절한 위치로 이동하는 일

</br>

> **디스패처는 모든 프로세스의 문맥 교환 시 호출되므로, 가능한 한 빨리 수행되어야 한다.**

<img width="206" alt="image" src="https://user-images.githubusercontent.com/106216912/211205253-1dc5a5af-eb77-4269-b4c8-7192b0c8f241.png">

→ **디스패치 지연(dispatch latency)** : **디스패처가 하나의 프로세스를 정지하고, 다른 프로세스의 수행을 시작하는데까지 소요되는 시간**

</br>

> **자발적 문맥 교환과 비자발적 문맥 교환의 차이점**

- **자발적 문맥 교환** : 현재 사용 불가능한 자원을 요청했기 때문에, 프로세스가 CPU 제어를 포기한 경우 발생
- **비자발적 문맥 교환** : 타임 슬라이스가 만료되었거나, 우선순위가 더 높은 프로세스에 의해 선점된 경우와 같이 CPU를 빼앗겼을 때 발생

---

## 2. 스케줄링 기준

→ ***서로 다른 CPU 스케줄링 알고리즘들은 다른 특성을 갖고 있다.***

- 어떠한 알고리즘을 선택하려면, 다양한 알고리즘들의 서로 다른 특성을 고려해야 한다.

</br>

> **CPU 스케줄링 알고리즘을 비교하기 위한 여러 기준**

- **CPU 이용률(utilization)**
    - 우리는 가능한 한 CPU를 최대한 바쁘게 유지하기를 원한다.

</br>

- **처리량(throughput)**
    - **단위 시간당 완료된 프로세스의 개수**이다.

</br>

- **총처리 시간(turnaround time)**
    - 프로세스의 제출 시간과 완료 시간의 간격이다.
    - **준비 큐에서 대기한 시간 + CPU에서 실행하는 시간 + I/O 시간**

</br>

- **대기 시간(waiting time)**
    - **준비 큐에서 대기하면서 보낸 시간의 합**
    - 스케줄링 알고리즘은 프로세스가 준비 큐에서 대기하는 시간의 양에만 영향을 준다.

</br>

- **응답 시간(response time)**
    - **요구를 제출한 후, 첫 번째 응답이 나올 때까지의 시간**
    - 응답이 시작되는 데까지의 시간이고, 응답을 출력하는 데 걸리는 시간은 아니다.

</br>

> **CPU 이용률과 처리량은 최대화하고, 총처리 시간, 대기 시간, 응답 시간은 최소화하는 것이 바람직하다!**

- 대부분, 평균 측정 시간을 최적화하려고 한다.
    - 하지만 평균보다는 최솟값, 또는 최댓값을 최적화하는 것이 바람직할 수도 있다.

---

## 3. 스케줄링 알고리즘

→ ***CPU 스케줄링은 준비 큐에 있는 어느 프로세스에 CPU 코어를 할당할 것인지를 결정한다.***

- 여러 가지 다른 CPU 스케줄링 알고리즘이 존재한다.
    - 이 절에서는, 스케줄링 알고리즘을 처리 코어가 하나뿐이라고 가정하고 설명한다.

</br>

### 선입 선처리 스케줄링(First-Come, First-Served Scheduling)

→ ***가장 간단한 CPU 스케줄링 알고리즘은 선입 선처리(FCFS) 스케줄링 알고리즘이다.***

- **CPU를 먼저 요청하는 프로세스가 CPU를 먼저 할당받는다!**
    - 선입선출(FIFO) 큐로 쉽게 관리할 수 있다.
    - **단점 : 평균 대기 시간이 종종 대단히 길 수 있다.**

</br>

> **FCFS 스케줄링 알고리즘의 예시**

- 프로세스들은 **P1, P2, P3 순으로 도착**하고, 선입 선처리 순으로 서비스받는다고 가정한다.

<img width="243" alt="image" src="https://user-images.githubusercontent.com/106216912/211245871-83368fe9-3421-4cbf-a71a-8d96b32098c2.png">

</br>

→ 결과는 다음 Gantt 차트와 같다.

<img width="485" alt="image" src="https://user-images.githubusercontent.com/106216912/211245936-957f593f-5cd8-492d-bb2e-5dc447155bf4.png">

- **평균 대기 시간 : (0 + 24 + 27) / 3 = 17밀리초**

</br>

→ 프로세스들이 **P2, P3, P1 순으로 도착**하면, 결과는 다음과 같다.

<img width="483" alt="image" src="https://user-images.githubusercontent.com/106216912/211246012-f87f1cf2-acee-4fe6-9c52-311576bf6634.png">

- **평균 대기 시간 : (6 + 0 + 3) / 3 = 3밀리초**
    - **평균 대기 시간은 일반적으로 최소가 아니며, 프로세스 CPU 버스트 시간이 변할 경우에는 평균 대기 시간도 변할 수 있다!**

</br>

> **동적 상황에서의 선입 선처리 스케줄링의 성능**

1. CPU 중심 프로세스가 CPU를 할당받아서 점유한다.
    - 그동안 다른 모든 프로세스는 입출력을 끝내고, 준비 큐로 이동하여 CPU를 기다릴 것이다.
    - 프로세스들이 준비 큐에서 기다리는 동안, I/O 장치들은 쉬고 있다.

</br>

2. CPU 중심 프로세스가 자신의 CPU 버스트를 끝내고, I/O 장치로 이동한다.
    - 모든 I/O 중심의 프로세스들은 매우 짧은 CPU 버스트를 갖고 있기 때문에, CPU 작업을 신속하게 끝내고 다시 I/O 큐로 이동한다.
    - 이 시점에서, CPU가 쉬게 된다.

</br>

3. CPU 중심 프로세스는 다시 준비 큐로 이동해, CPU를 할당받는다.
    - CPU 중심 프로세스가 끝날 때까지 모든 I/O 프로세스들은 다시 준비 큐에서 기다리게 된다.

</br>

→ **호위 효과(convoy effect)** : **모든 다른 프로세스들이 하나의 긴 프로세스가 CPU를 양도하기를 기다리는 것**

- 짧은 프로세스들이 먼저 처리되도록 할 때보다 **CPU와 장치 이용률이 저하**된다.

</br>

> **비선점형이란**

→ ***CPU가 한 프로세스에 할당되면, 그 프로세스가 종료하든지, I/O 처리를 요구하든지 하여 CPU를 방출할 때까지 CPU를 점유한다.***

- **선입 선처리 알고리즘은 대화형 시스템에서 문제**가 된다.
    - 대화형 시스템에서는 각 프로세스가 규칙적인 간격으로 CPU의 몫을 얻는 것이 매우 중요하기 때문이다.

</br>

### 최단 작업 우선 스케줄링(Shortest-Job-First Scheduling)

→ ***CPU 스케줄링의 다른 접근 방법은 최단 작업 우선(SJF) 알고리즘이다.***

- 각 프로세스에 다음 CPU 버스트 길이를 연관시킨다.
    - **CPU가 이용 가능해지면, 다음 CPU 버스트가 가장 짧은 프로세스에게 할당한다!**
        - 만약 **길이가 동일하다면, 순위를 정하기 위해 선입 선처리 스케줄링을 적용**한다.
    - 프로세스의 전체 길이가 아니라, 다음 CPU 버스트의 길이에 의해 스케줄링 된다.

</br>

> **SJF 스케줄링 알고리즘의 예시**

<img width="241" alt="image" src="https://user-images.githubusercontent.com/106216912/211246427-f1e12eaf-7d27-4fd1-a11d-6c9869be002c.png">

</br>

→ **SJF 스케줄링을 이용**하면, 결과는 다음의 Gantt 차트와 같다.

<img width="483" alt="image" src="https://user-images.githubusercontent.com/106216912/211246507-57690212-9644-4e31-890a-11fa5c53646a.png">

- **평균 대기 시간 : (3 + 16 +9 + 0) / 4 = 7밀리초**
    - **선입 선출 스케줄링을 사용했다면, 10.25밀리초**이다.

</br>

> **SJF 스케줄링 알고리즘은 주어진 프로세스 집합에 대해 최소의 평균 대기 시간을 가지므로, 최적이다.**

- 짧은 프로세스의 대기 시간은 줄이고, 긴 프로세스의 대기 시간은 증가한다.
    - **결과적으로, 평균 대기 시작이 줄어든다.**

</br>

→ **SJF 알고리즘은 최적이긴 하지만 CPU 스케줄링 수준에서는 구현할 수 없다!**

- **다음 CPU 버스트의 길이를 알 방법이 없기 때문**이다.
    - 다음 CPU 버스트의 길이를 알 수는 없으나, 그 값을 예측해 근삿값을 사용할 수는 있다.
        - 다음 CPU 버스트가 앞의 버스트와 길이가 유사하다고 간주한다.

<img width="430" alt="image" src="https://user-images.githubusercontent.com/106216912/211246594-e093ae5b-e5a7-4d56-8a16-05e45733950c.png">

</br>

> **SJF 알고리즘은 선점형이거나, 또는 비선점형일 수 있다.**

- **선점형**
    - **새로운 프로세스가 현재 실행되고 있는 프로세스의 남은 시간보다도 짧은 버스트를 가지면, 현재 실행중인 프로세스를 선점**한다.

</br>

- **비선점형**
    - **실행중인 프로세스가 CPU 버스트를 완료할 때까지 선점하지 않고, 자신의 CPU 버스트를 끝내도록 허용**한다.

</br>

→ 선점형 SJF 알고리즘 = **최소 잔여 시간 우선 스케줄링(shortest remaining time first)**

</br>

> **선점형 SJF 스케줄링 알고리즘의 예시**

<img width="378" alt="image" src="https://user-images.githubusercontent.com/106216912/211246658-30527921-b7e0-4c8e-bffe-e82278d3f5c1.png">

</br>

→ **선점형 SJF 스케줄을 사용**하면, 결과는 다음의 Gantt 차트와 같다.

<img width="532" alt="image" src="https://user-images.githubusercontent.com/106216912/211246722-fd71af51-5af1-4134-9ca3-2a2201341a05.png">

- **비선점형일 때의 평균 대기 시간 : (0 + 7 + 15 + 9) / 4 = 7.75밀리초**
- **선점형일 때의 평균 대기 시간 : (9 + 0 + 15 + 2) / 4 = 6.5밀리초**

</br>

### 라운드 로빈 스케줄링(Round-Robin Scheduling)

→ ***라운드 로빈(RR) 스케줄링 알고리즘은 선입 선처리와 유사하지만, 시스템이 프로세스들 사이를 옮겨 다닐 수 있도록 선점이 추가된다.***

- **시간 할당량(time quantum), 또는 타임슬라이스(time slice)** 라고 하는 작은 단위의 시간을 사용한다.
    - CPU 스케줄러는 준비 큐를 돌면서 **한 번에 한 프로세스에 한 번의 시간 할당량 동안 CPU를 할당**한다.

</br>

> **라운드 로빈 스케줄링의 구현**

- 준비 큐가 선입 선출 큐로 동작하게 만든다.
    - 새로운 프로세스들은 준비 큐의 꼬리에 추가된다.
    - CPU 스케줄러는 준비 큐에서 첫 번째 프로세스를 선택해 한 번의 시간 할당량 이후에 인터럽트를 걸도록 타이머를 설정한 후, 프로세스를 디스패치 한다.

</br>

- 두 가지 경우 중 하나가 발생한다.
    1. 프로세스의 CPU 버스트가 한 번의 시간 할당량 보다 작은 경우에는, 프로세스 자신이 CPU를 자발적으로 방출하고, 스케줄러는 준비 큐에 있는 다음 프로세스로 진행한다.
    2. 현재 실행 중인 프로세스의 CPU 버스트가 한 번의 시간 할당량 보다 긴 경우로, 타이머가 끝나면서 인터럽트가 발생한다.
        - 그 후, 문맥 교환이 일어나고 실행하던 프로세스는 준비 큐의 꼬리에 넣어지고, CPU 스케줄러는 준비 큐의 다음 프로세스를 선택한다.

</br>

> **라운드 로빈 스케줄링 알고리즘의 예시**

<img width="238" alt="image" src="https://user-images.githubusercontent.com/106216912/211246817-288ee6f0-f10a-4f96-94fe-e4466f05b080.png">

</br>

→ **라운드 로빈 스케줄**의 결과는 다음과 같다.

- **시간 할당량 : 4밀리초**

<img width="528" alt="image" src="https://user-images.githubusercontent.com/106216912/211246901-7ac706da-e387-4eaf-8d5f-77d8c801ba39.png">

- **평균 대기 시간 : (6 + 4 + 7) / 3 = 5.66밀리초**

</br>

> **라운드 로빈 스케줄링 알고리즘에서는, 유일하게 실행 가능한 프로세스가 아니라면 연속적으로 두 번 이상의 시간 할당량을 할당받는 프로세스는 없다!**
> 
- 만약 CPU 버스트가 한 번의 시간 할당량을 초과하면, 프로세스는 선점되고 준비 큐로 되돌아간다.
    
    → **RR 스케줄링 알고리즘은 선점형이다!**

</br>

> **RR 알고리즘의 성능은 시간 할당량의 크기에 매우 많은 영향을 받는다!**

- **시간 할당량이 매우 크면, 선입 선처리 정책과 같다.**
- **시간 할당량이 매우 적다면, 매우 많은 문맥 교환을 야기한다.**

<img width="480" alt="image" src="https://user-images.githubusercontent.com/106216912/211246966-e4dcd183-52a0-4044-a422-932152344733.png">

</br>

> **총처리 시간 또한 시간 할당량의 크기에 좌우된다.**

<img width="389" alt="image" src="https://user-images.githubusercontent.com/106216912/211247027-9a79a930-dd5b-4a0d-840a-e0f6c15b7437.png">

- 프로세스 집합의 평균 총처리 시간은 시간 할당량의 크기가 증가하더라도, 반드시 개선되지는 않는다.
    - **대부분의 프로세스가 단일 시간 할당량 안에 CPU 버스트를 끝낸다면, 평균 총처리 시간은 개선**된다.

</br>

- 문맥 교환 시간이 추가된다면 더 많은 문맥 교환이 요구된다.
    - 따라서, 더 작은 시간 할당량에 대해서는 평균 총처리 시간이 증가한다.

</br>

### 우선순위 스케줄링(Priority Scheduling)

→ ***SJF 알고리즘은 일반적인 우선순위 스케줄링 알고리즘의 특별한 경우이다.***

- **우선순위가 각 프로세스에게 주어지고, CPU는 가장 높은 우선순위를 가진 프로세스에 할당된다!**
    - **우선순위가 같은 프로세스들은 선입 선처리 순서로 스케줄** 된다.
    - SJF 알고리즘은 우선순위가 다음 CPU 버스트의 길이를 기준으로 하는 우선 순위 스케줄링 알고리즘의 특별한 경우이다.

</br>

- 우선순위는 일반적으로 0에서 7, 또는 0에서 4,095까지의 일정 범위의 수가 사용된다.
    - 하지만, 0이 무조건 최상위, 또는 최하위 우선순위는 아니다.
    - **시스템마다 낮은 값이 낮은 우선순위 인지, 높은 우선순위 인지는 다르다.**

</br>

> **우선순위 스케줄링의 예시**

<img width="340" alt="image" src="https://user-images.githubusercontent.com/106216912/211247108-1015b9b0-40b6-4c7f-a894-f2f155897c94.png">

</br>

→ **우선순위 스케줄링의 결과**는 다음과 같다.

<img width="525" alt="image" src="https://user-images.githubusercontent.com/106216912/211247156-7e720380-5155-42d6-8fd4-cc2a858ca47b.png">

- **평균 대기 시간 : (6 + 0 + 16 + 18 + 1) / 5 = 8.2밀리초**

</br>

> **우선순위는 내부적, 또는 외부적으로 정의될 수 있다.**

- **내부적 우선순위** : 프로세스의 우선순위를 계산하기 위해 어떤 측정 가능한 양들을 사용한다.
    - 시간 제한, 메모리 요구, 열린 파일의 수, 평균 CPU 버스트에 대한 비율 등

</br>

- **외부적 우선순위** : 프로세스의 중요성, 컴퓨터 사용을 위해 지불되는 비용의 유형과 양 등

</br>

> **우선순위 스케줄링은 선점형이거나, 비선점형일 수 있다.**

- **선점형** : **새로 도착한 프로세스의 우선순위가 현재 실행되는 프로세스의 우선순위보다 높다면, CPU를 선점**한다.

</br>

- **비선점형** : **단순히 준비 큐의 머리 부분에 새로운 프로세스를 넣는다.**

</br>

> **우선순위 스케줄링 알고리즘의 문제는 무한 봉쇄(indefinite blocking) 또는 기아 상태(starvation)이다.**
> 
- 부하가 과중한 컴퓨터 시스템에서는 높은 우선순위의 프로세스들이 꾸준히 들어와서, 낮은 우선순위의 프로세스들이 CPU를 얻지 못하게 될 수도 있다.
    - **낮은 우선순위 프로세스들이 CPU를 무한히 대기하는 경우가 발생한다!**

</br>

→ **첫 번째 해결 방안 : 노화(aging)**

- 에이징은 **오랫동안 시스템에서 대기하는 프로세스들의 우선순위를 점진적으로 증가**시킨다.
    - ex) 우선순위가 127(낮음)에서 0(높음)까지의 범위라면, 주기적으로(1초) 대기 중인 프로세스의 우선순위를 1씩 증가시킨다.

</br>

→ **두 번째 해결 방안 : 라운드 로빈과 우선순위 스케줄링을 결합하는 방법**

- **시스템이 우선순위가 가장 높은 프로세스를 실행하고, 우선순위가 같은 프로세스들은 라운드 로빈 스케줄링을 사용하여 스케줄링하는 방식**이다.

</br>

> **라운드 로빈과 우선순위 스케줄링을 결합하는 방법의 예시**

<img width="342" alt="image" src="https://user-images.githubusercontent.com/106216912/211247353-584761b7-d156-47ed-888a-f5cce139f799.png">

</br>

→ **우선순위 스케줄링을 사용하고, 우선순위가 같은 프로세스들은 라운드 로빈으로 스케줄링하면 결과**는 다음과 같다.

- **시간 할당량 : 2밀리초**

<img width="535" alt="image" src="https://user-images.githubusercontent.com/106216912/211247449-75293f2b-82b3-4d87-b269-671d008e4ce0.png">

- **평균 대기 시간 : (22 + 11 + 12 + 0 + 24) / 5 = 13.8밀리초**

</br>

### 다단계 큐 스케줄링(Multilevel Queue Scheduling)

→ ***우선순위와 라운드 로빈 스케줄링을 사용할 때, 모든 프로세스가 단일 큐에 배치되고 스케줄러는 우선순위가 가장 높은 프로세스를 선택하여 실행시킬 수 있다.***

<img width="244" alt="image" src="https://user-images.githubusercontent.com/106216912/211247508-ec58b268-db24-4e55-90a1-036e13b995ee.png">

- **다단계 큐** : **우선순위마다 별도의 큐를 갖는 것**이 더 쉬운 때도 있으며, 우선순위 스케줄링은 우선순위가 가장 높은 큐에서 프로세스를 스케줄한다.
    - 우선순위 스케줄링이 라운드 로빈과 결합한 경우, 효과적이다.
    - 우선순위가 가장 높은 큐에 여러 프로세스가 있는 경우, 라운드 로빈 순서로 실행된다.
    - 우선순위는 각 프로세스에 정적으로 할당되며, 프로세스는 실행시간 동안 동일한 큐에 남아 있다.

</br>

> **프로세스 유형에 따라 프로세스를 여러 개의 개별 큐로 분할하기 위해 다단계 큐 스케줄링 알고리즘을 사용할 수도 있다.**

<img width="437" alt="image" src="https://user-images.githubusercontent.com/106216912/211247585-0f81b147-3d6e-456e-918d-e673eab4bdad.png">

- ex) 포그라운드(대화형) 프로세스와 백그라운드(배치) 프로세스를 구분한다.
    - 두 유형의 프로세스는 응답 시간 요구 사항이 다르므로, 스케줄링 요구 사항이 다를 수 있다.

</br>

> **큐와 큐 사이에 스케줄링도 반드시 있어야 하며, 일반적으로 고정 우선순위의 선점형 스케줄링으로 구현된다.**

- 각 큐는 다음과 같은 우선순위를 갖는다.
    1. **실시간 프로세스**
    2. **시스템 프로세스**
    3. **대화형 프로세스**
    4. **배치 프로세스**

</br>

→ **각 큐는 낮은 우선순위의 큐보다 절대적인 우선순위를 가진다.**

→ **또한, 큐들 사이에 시간을 나누어 사용한다.**

</br>

### 다단계 피드백 큐 스케줄링(Multilevel Feedback Queue Scheduling)

→ ***다단계 큐 스케줄링 알고리즘에서는, 프로세스들이 시스템 진입 시에 영구적으로 하나의 큐에 할당된다.***

- 즉, 프로세스들은 큐들 사이로 이동하지 않는다.
    - **스케줄링 오버헤드는 적으나, 융통성이 적다.**

</br>

> **다단계 피드백 큐 스케줄링 알고리즘에서는 프로세스가 큐들 사이를 이동하는 것을 허용한다!**

<img width="390" alt="image" src="https://user-images.githubusercontent.com/106216912/211247648-2f886986-7549-4b4d-9920-a31d04e36b25.png">

- 프로세스들을 CPU 버스트 성격에 따라서 구분한다.
    - **어떤 프로세스가 CPU 시간을 너무 많이 사용하면 낮은 우선순위의 큐로 이동**된다.
    - **낮은 우선순위의 큐에서 너무 오래 대기하는 프로세스는 높은 우선순위의 큐로 이동**할 수 있다.

</br>

- 다단계 피드백 큐 스케줄링 알고리즘은 CPU 버스트가 8밀리초 이하인 모든 프로세스에게 최고의 우선순위를 부여한다.
    - 이러한 프로세스는 CPU를 빨리 할당받아서, CPU 버스트를 끝내고 다음의 I/O 버스트로 간다.

</br>

> **일반적으로, 다단계 피드백 큐 스케줄러는 다음의 매개변수에 의해 정의된다.**

- **큐의 개수**
- **각 큐를 위한 스케줄링 알고리즘**
- **한 프로세스를 높은 우선순위 큐로 올려주는 시기를 결정하는 방법**
- **한 프로세스를 낮은 우선순위 큐로 강등시키는 시기를 결정하는 방법**
- **프로세스에 서비스가 필요할 때 프로세스가 들어갈 큐를 결정하는 방법**

</br>

→ **가장 일반적인 CPU 스케줄링 알고리즘이다!**

- 설계 중인 특정 시스템에 부합하도록 구성 가능하다.
- **단점 : 매개변수들의 값을 선정하는 특정 방법이 필요하기 때문에, 가장 복잡하다.**

---

## 4. 스레드 스케줄링

→ ***최신 운영체제에서 스케줄 되는 대상은 프로세스가 아니라 커널 수준 스레드이다.***

- 사용자 수준 스레드는 스레드 라이브러리에 의해 관리되고, 커널은 그들의 존재를 알지 못한다.

</br>

### 경쟁 범위

→ ***사용자 수준 스레드와 커널 수준 스레드의 차이 중 하나는 어떻게 스케줄 되느냐에 있다.***

- **프로세스 경쟁 범위(PCS)**
    - 다대일 또는 다대다 모델을 구현하는 시스템에서는 스레드 라이브러리는 사용자 수준 스레드를 가용한 LWP상에서 스케줄 한다.
    - 전형적으로, PCS는 우선순위에 따라 행해진다.
        - 높은 우선순위의 스레드를 위하여 현재 실행 중인 스레드를 선점한다.

</br>

- **시스템-경쟁 범위(SCS)**
    - CPU 상에 어느 커널 스레드를 스케줄 할 것인지를 결정하기 위해 커널이 사용한다.

</br>

### Pthread 스케줄링

→ ***스레드를 생성하면서 PCS 또는 SCS를 지정할 수 있는 POSIX Pthreads API***

- Pthreads는 다음과 같은 범위 값을 구분한다.
    - PTHREAD SCOPE PROCESS : PCS 스케줄링을 사용하여 스레드를 스케줄 한다.
    - PTHREAD SCOPE SYSTEM : SCS 스케줄링을 사용하여 스레드를 스케줄 한다.

</br>

- 다대다 모델을 구현하는 시스템 : PTHREAD_SCOPE_PROCESS 정책이 사용자 수준 스레드를 가용한 LWP로 스케줄 한다.
- 일대일 모델이 사용되는 시스템 : PTHREAD_SCOPE_SYSTEM 정책은 각 사용자 수준 LWP를 생성하고, 바인드 하게 된다.

</br>

> **Pthread IPC는 경쟁 범위 정책의 정보를 얻어내고 지정하기 위하여 두 함수를 제공한다.**

- `pthread_attr_setscope(pthread_attr_t *attr, int scope)`
- `pthread_attr_getscope(pthread_attr_t *attr, int *scope)`

<img width="433" alt="image" src="https://user-images.githubusercontent.com/106216912/211348736-3924e334-3460-461b-8c74-dbb218b868bf.png">

---

## 5. 다중 처리기 스케줄링

→ ***여러 개의 CPU가 사용 가능하다면, 여러 스레드가 병렬로 실행될 수 있으므로 부하 공유가 가능해진다.***

- 하지만, **스케줄링 문제는 더욱 복잡해진다.**

</br>

- 최신 컴퓨팅 시스템에서는 다중 처리기는 여러 시스템 아키텍처들에 사용할 수 있다.
    - 다중 코어 CPU
    - 다중 스레드 코어
    - NUMA 시스템
    - 이기종 다중 처리

</br>

### 다중 처리기 스케줄링에 대한 접근 방법

→ ***다중 처리기 시스템의 CPU 스케줄링에 관한 한 가지 해결 방법이 존재한다.***

- **비대칭 다중 처리**
    - **마스터 서버라는 하나의 처리기가 모든 스케줄링 결정과 I/O 처리, 그리고 다른 시스템의 활동을 취급**하게 한다.
    - 다른 처리기들은 사용자 코드만을 수행한다.
    - **장점** : 하나의 코어만 시스템 자료구조에 접근하기 때문에, 자료 공유를 할 필요가 없어 간단하다.
    - **단점** : 마스터 서버가 전체 시스템 성능을 저하할 수 있는 병목이 된다.

</br>

- **대칭 다중 처리(SMP)**
    - **각 프로세서는 스스로 스케줄링** 할 수 있다.
    - 각 프로세서의 스케줄러가 준비 큐를 검사하고, 실행할 스레드를 선택하여 스케줄링이 진행된다.

</br>

→ **스케줄 대상이 되는 스레드를 관리하기 위한 두 가지 전략을 제공한다.**

<img width="393" alt="image" src="https://user-images.githubusercontent.com/106216912/211366963-5cddb729-aa86-4224-b52c-5f07a022967d.png">

1. **모든 스레드가 공통 준비 큐에 있을 수 있다.**
    - 공유 준비 큐에 경쟁 조건이 생길 수 있으므로, 두 개의 다른 프로세서가 동일한 스레드를 스케줄 하지 않도록, 또한 큐에서 스레드가 없어지지 않도록 보장해야 한다.
    - 공유 큐 액세스는 **성능의 병목**이 될 수 있다.

</br>
    
2. **각 프로세서는 자신만의 스레드 큐를 가질 수 있다.**
    - 각 프로세서가 자신만의 실행 큐에서 스레드를 스케줄 할 수 있도록 허용하므로, 성능 문제를 겪지 않는다.
    - 캐시 메모리를 효율적으로 사용할 수 있다.

</br>

> **큐마다 부하의 양이 다를 수 있다.**

→ **균형 알고리즘**을 사용하여 모든 프로세서 간에 부하를 균등하게 만들 수 있다.

</br>

### 다중 코어 프로세서

→ ***다중 코어 프로세서는 동일한 물리적인 칩 안에, 여러 개의 처리 코어를 장착한 것이다.***

- 각 코어는 구조적인 상태를 유지하고 있어, **운영체제 입장에서는 개별적인 논리적 CPU**처럼 보이게 된다.
    - 속도가 빠르고, 적은 전력을 소모한다.

</br>

> **다중 코어 프로세서는 스케줄링 문제를 복잡하게 한다.**

<img width="439" alt="image" src="https://user-images.githubusercontent.com/106216912/211367308-ed0b7d07-5a02-46f5-b268-f07811de6b4a.png">

- **메모리 스톨(memory stall)** : **프로세서가 메모리에 접근할 때 데이터가 가용해지기를 기다리면서 많은 시간을 허비**한다.
    - 캐시 미스(캐시 메모리에 없는 데이터를 액세스)등의 여러 원인으로 인해 발생한다.
    - 최대 50%의 시간을 허비할 수 있다.

</br>

→ **하나의 코어에 2개 이상의 하드웨어 스레드가 할당될 수 있는 다중 스레드 처리 코어를 구현한다!**

<img width="435" alt="image" src="https://user-images.githubusercontent.com/106216912/211367687-c0bac0ee-dfda-4ca2-b6d5-82707a067689.png">

- 메모리를 기다리는 동안 하나의 하드웨어 스레드가 중단되면, 코어가 다른 스레드로 전환할 수 있다.

</br>

> **칩 다중 스레딩(CMT)**

<img width="248" alt="image" src="https://user-images.githubusercontent.com/106216912/211367809-09dfe6b4-6689-46d9-9baa-b18726edf69a.png">

- 운영체제 관점에서 각 하드웨어 스레드는 명령어 포인터 및 레지스터 집합과 같은 구조적 상태를 유지하므로, 소프트웨어 스레드를 실행할 수 있는 논리적 CPU로 보인다.

</br>

- **하이퍼-스레딩(동시 다중 스레딩)** : 단일 하드웨어 코어에 여러 하드웨어 스레드를 할당하는 것

</br>

> **처리기를 다중 스레드화 하는 데에는 거친(coarse-grained) 다중 스레딩과, 세밀한(fine-grained) 다중 스레딩의 두 가지 방법이 있다.**

- **거친 다중 스레딩**
    - 스레드가 메모리 스톨과 같은 긴 지연시간을 가진 이벤트가 발생할 때까지 한 코어에서 수행된다.
    - 긴 지연시간을 가진 이벤트에 의한 지연 때문에, 코어는 다른 스레드를 실행하게 된다.

</br>

- **세밀한 다중 스레딩**
    - 명령어 주기의 경계에서와 같이 좀 더 세밀한 정밀도를 가진 시스템에서 스레드 교환이 일어난다.

</br>

> **결과적으로, 다중 스레드 다중 코어 프로세서는 현실적으로 두 단계의 스케줄링 단계가 필요하다.**

<img width="316" alt="image" src="https://user-images.githubusercontent.com/106216912/211368041-0b3a1108-7f56-4a10-8d4d-2635c47f8415.png">

- **첫 번째 단계**
    - **운영체제가 각 하드웨어 스레드에서 실행할 소프트웨어 스레드를 선택할 때 결정해야 하는 스케줄링 결정**을 한다.

</br>

- **두 번째 단계**
    - **각 코어가 실행할 하드웨어 스레드를 결정하는 방법을 명시**한다.

</br>

→ **두 가지 스케줄링 단계가 반드시 상호 배타적일 필요는 없다!**

- 운영체제 스케줄러가 프로세서 자원 공유를 인식하면 보다 효과적인 스케줄링 결정을 내릴 수 있다.

</br>

### 부하 균등화

→ ***SMP 시스템에서 처리기가 하나 이상이라는 것을 최대한 활용하려면, 부하를 모든 처리기에게 균등하게 배분하는 것이 매우 중요하다.***

- 그렇지 않으면, 다른 처리기들이 부하를 가지고 있고, 준비 큐에 처리기를 기다리는 스레드들이 많은 상황에서 하나 이상의 처리기가 쉬게 된다.

</br>

→ **부하 균등화(load balancing)** : SMP 시스템의 모든 처리기 사이에 부하가 고르게 배분되도록 시도한다.

- 각 처리기가 실행할 스레드를 위한 자기 자신만의 준비 큐를 가지고 있는 시스템에서만 필요하다.

</br>

> **부화 균등화는 push 이주(migration), pull 이주 방식의 두 가지 일반적인 접근법이 있다.**

- **push 이주**
    - 특정 태스크가 주기적으로 각 처리기의 부하를 검사하고, **불균형 상태로 밝혀지면 과부하인 처리기에서 쉬고 있거나 덜 바쁜 처리기로 스레드를 이동**시킨다.

</br>

- **pull 이주**
    - **쉬고 있는 처리기가 바쁜 처리기를 기다리고 있는 프로세스를 가져와 실행**시킨다.

</br>

→ **이 두 방법은 상호 배타적일 필요는 없으며, 부화 균등화 시스템에서 종종 병렬적으로 구현된다!**

</br>

### 처리기 선호도

→ ***스레드가 특정 처리기에서 실행 중일 때 캐시 메모리에 어떤 일이 벌어질까?***

- 스레드에 의해 가장 최근에 접근된 데이터가 그 처리기의 캐시를 채우고, 결과 스레드에 의한 잇따른 메모리 접근은 캐시 메모리에서 만족한다.
    - 스레드가 다른 처리기로 이주한다면 첫 번째 프로세서의 캐시 메모리 내용은 무효화 되어야 하고, 두 번째 프로세서의 캐시는 다시 채워져야 한다.

</br>

→ **프로세서 선호도** : 캐시 무효화 및 다시 채우는 비용이 많이 들기 때문에, **SMP 시스템들은 스레드를 한 프로세서에서 다른 프로세서로 이주시키지 않고 같은 프로세서에서 계속 실행시키려 한다.**

</br>

> **처리기 선호도는 여러 형태를 갖고 있다.**

- **약한 선호도(soft affinity)**
    - 운영체제가 동일한 처리기에서 프로세스를 실행시키려고 노력하는 정책을 가지지만, 보장하지는 않는다.
    - 프로세스가 처리기 사이에서 이주하는 것이 가능하다.

</br>

- **강한 선호도(hard affinity)**
    - 프로세스가 다른 처리기로 이주하지 않게 지정이 가능하다.

</br>

> **시스템의 메인 메모리 구조가 프로세서 선호도 문제에 영향을 줄 수 있다.**

<img width="464" alt="image" src="https://user-images.githubusercontent.com/106216912/211368552-77de545f-1489-4610-babd-1387c548b251.png">

- 시스템 연결망을 통해 NUMA 시스템의 모든 CPU가 하나의 물리적 주소 공간을 공유할 수 있다.
    - CPU는 다른 CPU의 로컬 메모리보다 자신의 로컬 메모리에 더 빠르게 액세스할 수 있다.

</br>

> **부하 균등은 프로세서 선호도의 이점을 상쇄한다.**

→ **동일한 프로세서에서 스레드를 계속 실행하면, 스레드가 해당 프로세서의 캐시 메모리에 있는 데이터를 활용할 수 있다.**

- **부화 균등화와 메모리 액세스 시간 최소화 사이에는 갈등이 생긴다!**

</br>

### 이기종 다중 처리

→ **메모리 액세스 시간이 NUMA 시스템 뿐만 아니라, 부화 균등화 및 프로세서 선호도 정책에 따라 달라질 수 있다.**

- **이기종 다중 처리(HMP)**
    - 일부 시스템은 동일한 명령어 집합을 실행하지만, 전력 소비를 유후 수준으로 조정하는 기능을 포함하여 클럭 속도 및 전력 관리 측면에서 차이가 나는 코어를 사용하여 설계되었다.

---

## 6. 실시간 CPU 스케줄링

→ ***실시간 운영체제에서 CPU를 스케줄링 할 때는 특별한 쟁점을 고려해야 한다.***

> **일반적으로 연성(soft) 실시간 시스템과 경성(hard) 실시간 시스템으로 구분한다.**

- **연성 실시간 시스템**
    - 중요한 실시간 프로세스가 스케줄 되는 시점에 관해 아무런 보장을 하지 않는다.
    - 중요 프로세스가 그렇지 않은 프로세스들에 비해 우선권을 가진다는 것만 보장한다.

</br>

- **경성 실시간 시스템**
    - 더 엄격한 요구 조건을 만족시켜야 한다.
    - 태스크는 반드시 마감시간까지 서비스를 받아야 하며, **마감시간이 지난 이후에 서비스를 받는 것은 서비스를 전혀 받지 않는 것과 같다.**

</br>

### 지연시간 최소화

→ ***시스템은 일반적으로 실시간으로 발생하는 이벤트를 기다린다.***

- 이벤트는 소프트웨어적으로 발생하기도 하고, 하드웨어적으로 발생하기도 한다.
    - **이벤트가 발생하면, 시스템은 가능한 빨리 응답을 하고, 그에 맞는 동작을 수행해야 한다.**

</br>

> **이벤트 지연시간**

→ **이벤트가 발생해서 그에 맞는 서비스가 수행될 때까지의 시간**

<img width="317" alt="image" src="https://user-images.githubusercontent.com/106216912/211475965-5884a6b2-0b75-4f7e-979b-771126d4fb96.png">

- 이벤트가 다르면, 그에 따른 지연시간 역시 다르다.

</br>

> **다음의 두 가지 유형의 지연시간이 실시간 시스템의 성능을 좌우한다.**

1. **인터럽트 지연시간**
2. **디스패치 지연시간**

</br>

> **인터럽트 지연시간**

→ **CPU에 인터럽트가 발생한 시점부터, 해당 인터럽트 처리 루틴이 시작하기까지의 시간**

<img width="330" alt="image" src="https://user-images.githubusercontent.com/106216912/211476088-47aa79e9-55ac-4586-b7ae-de117483608b.png">

- 인터럽트가 발생하면, 운영체제는 우선 수행 중인 명령어를 완수하고 발생한 인터럽트의 종류를 결정한다.
    - **인터럽트 서비스 루틴(ISR)** 을 사용하여 인터럽트를 처리하기 전에 현재 수행 중인 프로세스의 상태를 저장한다.

</br>

→ **실시간 태스크가 즉시 수행될 수 있도록 인터럽트 지연시간을 최소화하는 것은 실시간 운영체제에 매우 중요한 일이다.**

- 인터럽트 지연시간에 영향을 주는 요인 중 하나는, 커널 데이터 구조체를 갱신하는 동안 인터럽트가 불능케 되는 시간이다.
    - 실시간 운영체제는 인터럽트 불능 시간을 매우 짧게 해야 한다!

</br>

> **디스패치 지연시간**

→ ***스케줄링 디스패처가 하나의 프로세스를 블록시키고 다른 프로세스를 시작하는 데까지 걸리는 시간***

- **CPU를 즉시 사용해야 하는 실시간 태스크가 있다면, 이 지연 시간을 최소화**해야 한다.
    - 선점형 커널이 가장 효과적인 방법이다.

</br>

<img width="402" alt="image" src="https://user-images.githubusercontent.com/106216912/211476414-56bad90f-3a51-48e1-ab44-f4a5af2427e4.png">

- **디스패치 지연시간의 충돌 단계는 두 가지 요소로 구성되어 있다.**
    1. 커널에서 동작하는 프로세스에 대한 선점
    2. 높은 우선순위의 프로세스가 필요한 자원을 낮은 우선순위 프로세스 자원이 방출

</br>

### 우선순위 기반 스케줄링

→ ***실시간 운영체제에서 가장 중요한 기능은 실시간 프로세스에 CPU가 필요할 때 바로 응답을 해주는 것이다.***

- 따라서, 실시간 운영체제의 스케줄러는 **선점을 이용한 우선순위 기반의 알고리즘**을 지원해야 한다.
    - 각각의 프로세스에 중요성에 따라서 그 우선순위를 부여한다.
        - 더 중요한 태스크, 또한 실시간 프로세스에게 가장 높은 스케줄링 우선권을 부여한다.

</br>

> **선점 및 우선순위 기반의 스케줄러를 제공하는 것은, 단지 연성 실시간 기능을 제공하는 것에 불과하다.**

- 경성 실시간 시스템에서는 **실시간 태스크가 마감시간 내에 확실히 수행되는 것을 보장해야만 한다.**
    - 따라서 부가적인 스케줄링 기법이 필요하다!

</br>

> **스케줄 될 프로세스들의 특성**

<img width="432" alt="image" src="https://user-images.githubusercontent.com/106216912/211476631-69e411b0-d2fe-4d54-a602-5154b2e2f5ea.png">

1. **프로세스들은 주기적이다.**
    - 스케줄러는 이들 주기, 마감시간, 수행 시간 사이의 관계를 이용해서 마감시간과 주기적 프로세스의 실행 빈도에 따라 우선순위를 정한다.

</br>

2. **프로세스가 자신의 마감시간을 스케줄러에게 알려야만 할 수도 있다.**
    - 승인 제어 알고리즘을 이용해서 스케줄러는 마감시간 이내에 완수할 수 있는 프로세스는 실행을 허용하고, 아니면 요구를 거절한다.

</br>

### Rate-Monotonic 스케줄링

→ ***Rate-Monotonic 스케줄링 알고리즘은 선점 가능한 정적 우선순위 정책을 이용해서 주기 태스크들을 스케줄 한다.***

- **높은 우선순위의 프로세스가 낮은 우선순위의 프로세스를 선점**한다.

</br>

> **각각의 주기 태스크들은 시스템에 진입하면, 주기에 따라서 우선순위가 정해진다.**
> 
- **주기가 짧은 태스크는 높은 우선순위, 주기가 길면 낮은 우선순위가 배정**된다.
    - CPU를 더 자주 필요로 하는 태스크에 더 높은 우선순위를 주려는 목적이다.

</br>

- 주기 프로세스들의 처리 시간은 각각의 CPU 버스트와 같다고 가정한다.
    - 프로세스가 CPU를 차지한 시간 = CPU 버스트 시간

</br>

> **두 개의 프로세스 P1, P2가 있다고 가정한다.**

- **P1의 주기 : 50, P2의 주기 : 100**
- **P1의 수행 시간 : 20, P2의 수행 시간 : 35**
    - 각 프로세스의 마감 시간 : 다음 주기가 시작하기 전까지

<img width="439" alt="image" src="https://user-images.githubusercontent.com/106216912/211476805-10f5efe8-0bb4-4b67-8ecb-812f4f934059.png">

→ **P1의 마감시간이 50이기 때문에, 스케줄러는 P1의 마감시간을 충족시키지 못한다.**

</br>

> **Rate-monotonic 스케줄링을 사용한 방법**

- P1의 주기가 P2의 주기보다 짧으므로, P1의 우선순위가 P2의 우선순위보다 높다.

<img width="486" alt="image" src="https://user-images.githubusercontent.com/106216912/211476869-bba8d78b-c081-445f-889a-7fb82c11bd68.png">

1. P1이 먼저 수행을 시작하고, 시간 20에 수행을 끝낸다.
2. 바로 P2가 수행을 시작해서, 시간 50까지 수행을 끝낸다.
3. P1에게 선점되어 시간 70까지 수행을 하고, 스케줄러는 다시 남은 5만큼의 P2를 수행시킨다.

→ **모두 자신들의 마감시간을 만족할 수 있다!**

</br>

> **Rate-monotonic 스케줄링 기법이 스케줄 할 수 없는 경우**

- **P1의 주기 : 50, P2의 주기 : 80**
- **P1의 수행 시간 : 25, P2의 수행 시간 : 35**

<img width="487" alt="image" src="https://user-images.githubusercontent.com/106216912/211476944-649c2377-1084-4fb2-b0ca-91c21d05001f.png">

1. P1이 먼저 선점하여 시간 25까지 수행된다.
2. 다음 P2가 수행을 시작하여 시간 50까지 수행 후, P1에 선점된다.
3. P1이 시간 75까지 수행되고, P2는 시간 80에 **자신의 마감시간을 충족시키지 못한다!**

</br>

→ 시스템에 한 개의 프로세스만 존재한다면 CPU 이용률은 100%지만, 프로세스의 수가 증가함에 따라 69%까지 떨어진다.

</br>

### Earliest-Deadline-First 스케줄링

→ ***EDF 스케줄링 기법은 마감시간에 따라서 우선순위를 동적으로 부여한다.***

- **마감시간이 빠를수록 우선순위는 높아지고, 늦을수록 낮아진다.**
    - 프로세스가 실행 가능하게 되면 자신의 마감시간을 시스템에 알려야 한다.

</br>

> **Earliest-Deadline-First 스케줄링의 예시**

- **P1의 주기 : 50, P2의 주기 : 80**
- **P1의 수행 시간 : 25, P2의 수행 시간 : 35**

<img width="482" alt="image" src="https://user-images.githubusercontent.com/106216912/211477161-959b0965-915a-4032-9f41-342fed6fe603.png">

1. 처음에는 P1의 마감시간이 더 빠르기 때문에 P1이 먼저 시작한다.
2. P2는 P1의 CPU 버스트가 끝난 후 수행을 시작한다.
3. 하지만, rate-monotonic 과는 달리, 시간 50의 다음 주기에 P1이 P2를 선점하지 않고 P2가 계속 수행된다.
    - **P2의 마감시간(80)이 P1의 마감시간(100)보다 더 빠르기 때문에 P2의 우선 순위가 더 높다!**

</br>

→ **EDF 스케줄링 알고리즘은 프로세스들이 주기적일 필요도 없고, CPU 할당 시간도 상수 값으로 정해질 필요가 없다.**

- 하지만, 프로세스가 실행 가능해질 때 자신의 마감시간을 스케줄러에게 알려주어야 한다.
    - 이론적으로는 최적이다!

</br>

### 일정 비율의 몫 스케줄링

→ ***일정 비율의 몫 스케줄러는 모든 응용들에 T개의 시간 몫을 할당하여 동작한다.***

- 한 개의 응용이 N개의 시간 몫을 할당받으면 그 응용은 모든 프로세스 시간 중 N/T 시간을 할당받게 된다.
    - 일정 비율의 몫 스케줄러는 응용이 시간 몫을 할당받는 것을 보장하는 승인 제어 정책과 함께 동작해야만 한다.

</br>

### POSIX 실시간 스케줄링

→ ***POSIX는 실시간 컴퓨팅용으로 POSIX.1b라는 확장을 제공한다.***

- POSIX는 실시간 스레드를 위하여 두 개의 스케줄링 클래스를 정의한다.
    - SCHED FIFO
    - SCHED RR

</br>

- POSIX API는 스케줄링 정책에 관한 정보를 지정하고 얻어내는 두 개의 함수를 제공한다.
    - `pthread_attr_getschedpolicy(pthread_attr_t *attr, int *policy)`
    - `pthread_attr_setschedpolicy(pthread_attr_t *attr, int policy)`

---