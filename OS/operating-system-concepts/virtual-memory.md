> **가상 메모리** → **프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법**

- 장점 : **사용자 프로그램이 물리 메모리보다 커져도 된다.**
    - 가상 메모리는 물리 메모리로부터 프로그래머 관점의 논리 메모리를 분리해, 메인 메모리를 균일한 크기의 저장 공간으로 구성된 엄청나게 큰 배열로 추상화시켜 준다!

</br>

- 또한, **가상 메모리는 파일과 라이브러리의 공유를 쉽게 해주고 공유 메모리 구현을 가능**하게 한다.
    - 하지만, 이러한 가상 메모리는 구현하기 어렵다.
    - 또한, 잘못 사용하게 된다면 성능이 현저히 저하될 수 있다.

---

## 1. 배경

→ ***프로그램을 일부분만 메모리에 올려놓고 실행할 수 있다면 많은 이점이 있다.***

1. **프로그램은 물리 메모리 크기에 의해 더는 제약받지 않게 된다.**
    - 사용자들은 매우 큰 가상 주소 공간을 가정하고 프로그램을 만들 수 있으므로, 프로그래밍 작업이 간단해진다.

</br>

2. **각 프로그램이 더 작은 메모리를 차지하므로, 더 많은 프로그램을 동시에 수행할 수 있다.**
    - 응답 시간은 늘어나지 않으면서도 CPU 이용률과 처리율이 높아진다.

</br>

3. **프로그램을 메모리에 올리고 스왑하는 데 필요한 I/O 횟수가 줄어들기 때문에 프로그램들이 보다 빨리 실행된다.**

</br>

→ **프로그램의 일부만을 메모리에 올려놓고 실행하면, 시스템과 사용자 모두에게 이득이 된다!**

</br>

> **가상 메모리는 실제의 물리 메모리 개념과 개발자의 논리 메모리 개념을 분리한 것이다.**

- 장점 : **작은 메모리를 가지고도 얼마든지 큰 가상 주소 공간을 프로그래머에게 제공**할 수 있다.
    - 프로그래머는 메모리 크기에 관련한 문제를 염려할 필요 없이, 실제 해결하는 문제에만 집중할 수 있게 된다.

<img width="434" alt="image" src="https://user-images.githubusercontent.com/106216912/221362082-7daab735-3b17-434e-974b-3442ac470b98.png">

</br>

> **한 프로세스의 가상 주소 공간은 그 프로세스가 메모리에 저장되는 논리적인 모습을 말한다.**

<img width="191" alt="image" src="https://user-images.githubusercontent.com/106216912/221362111-4c97d026-e0c5-41fb-9d16-3e7192cbce92.png">

- 일반적으로, 특정 논리 주소에서 시작하여 연속적인 공간을 차지한다.
    - **힙(heap)** 은 동적 할당 메모리를 사용함에 따라 주소 공간상에서 위쪽으로 확장된다.
    - **스택(stack)** 또한 함수 호출을 거듭함에 따라 주소 공간상에서 아래쪽으로 확장된다.
        - 힙과 스택 사이의 공백도 가상 주소 공간의 일부이지만, 힙 또는 스택이 확장되어야만 실제 물리 페이지를 요구하게 될 것이다.

</br>

→ 공백을 포함하는 가상 주소 공간을 **성긴 주소 공간**이라고 한다!

- **성긴 주소 공간의 공백은 스택이나 힙 세그먼트가 확장될 때 사용되거나 프로그램 실행 중 동적으로 라이브러리를 링크할 필요가 있을 때 사용**된다.

</br>

> **가상 메모리는 또한 페이지 공유를 통해 파일이나 메모리가 둘 또는 그 이상의 프로세스들에 의해 공유되는 것을 가능하게 한다!**

→ ***이는 다음과 같은 장점을 갖는다.***

<img width="435" alt="image" src="https://user-images.githubusercontent.com/106216912/221362641-76fc60a4-df22-4720-ac56-3f6901f3f904.png">

1. **시스템 라이브러리가 여러 프로세스들에 공유될 수 있다.**
    - 각 프로세스는 라이브러리가 자신의 가상 주소 공간 일부라고 생각하지만, 실제로는 라이브러리가 존재하는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다.

</br>

2. **프로세스들이 메모리를 공유할 수 있다.**
    - 가상 메모리는 한 프로세스가 다른 프로세스와 공유할 수 있는 영역을 만들 수 있도록 해 준다.

</br>

3. **페이지는 `fork()` 시스템 콜을 통한 프로세스 생성 과정 중에 공유될 수 있기 때문에 프로세스 생성 속도를 높일 수 있다.**

---

## 2. 요구 페이징

→ ***어떻게 실행 프로그램을 보조저장장치에서 메모리로 적재할 수 있을까?***

1. 프로그램 실행 시작 시 프로그램의 전부를 물리 메모리에 적재한다.
    - 문제 : 초기에는 프로그램의 전체가 메모리에 있을 필요는 없을지도 모른다.

</br>

2. 필요한 페이지만 적재한다.
    - 이 방법은 **요구 페이징(demand paging)** 이라고 하며, 가상 메모리 시스템에서 일반적으로 사용된다.
        - 요구 페이징 가상 메모리를 사용하면 **프로그램 실행 중 필요할 때만 페이지가 적재**된다.
        - 접근되지 않은 페이지는 물리 메모리로 적재되지 않는다.

</br>

### 기본 개념

→ ***요구 페이징의 기본 개념은 필요할 때만 페이지를 메모리에 적재하는 것이다.***

- 결과적으로 프로세스가 실행되는 동안 일부 페이지는 메모리에 있고, 일부는 보조저장장치에 있다.
    - **따라서, 이 둘을 구별하기 위해 하드웨어 지원이 필요하다!**

</br>

<img width="438" alt="image" src="https://user-images.githubusercontent.com/106216912/221364427-21478318-b3b4-4d17-bd28-0b67df4ea415.png">

- 유효, 무효 비트 기법이 사용될 수 있다.
    - **유효(valid)** : 해당 페이지가 메모리에 있다.
    - **무효(invalid)** : 해당 페이지가 유효하지 않거나, 유효하지만 보조저장장치에 존재한다.

</br>

> **그러나, 프로세스가 메모리에 올라와 있지 않은 페이지에 접근하려고 하면 어떠한 일이 발생할까?**

- 이때, 페이지 테이블 항목이 무효로 설정되어 있으므로 **페이지 폴트 트랩**을 발생시킨다.
    - 페이징 하드웨어는 페이지 테이블을 이용한 주소 변환 과정에서 무효 비트를 발견하고 운영체제에 트랩을 건다.

</br>

> **페이지 폴트를 처리하는 과정**

<img width="528" alt="image" src="https://user-images.githubusercontent.com/106216912/221364487-76621a4f-252e-49e1-b0f0-0f0985a91953.png">

1. 프로세스에 대한 내부 테이블(internal table)을 검사해서 그 메모리 참조가 유효, 무효인지를 알아낸다.
2. 만약 무효한 페이지에 대한 참조라면, 그 프로세스는 중단된다.
    - 유효한 참조인데 페이지가 아직 메모리에 올라오지 않았다면, 그것을 보조저장장치로부터 가져와야 한다.
3. 빈 공간, 즉 가용 프레임을 찾는다.
4. 보조 저장장치에 새로이 할당된 프레임으로 해당 페이지를 읽어 들이도록 요청한다.
5. 보조저장장치 읽기가 끝나면, 이 페이지가 이제는 메모리에 있다는 것을 알리기 위해 페이지 테이블을 갱신한다.
    - 또한, 프로세스가 유지하고 있는 내부 테이블을 수정한다.
6. 트랩에 의해 중단되었던 명령어를 다시 수행한다.
    - 이제 프로세스는 마치 그 페이지가 항상 메모리에 있었던 것처럼 해당 페이지에 접근할 수 있다.

</br>

> **극단적인 경우에는 메모리에 페이지가 하나도 안 올라와 있는 상태에서도 프로세스를 실행시킬 수 있다.**

- 운영체제에서 명령 포인터의 값을 프로세스의 첫 명령으로 설정하는 순간, 이 명령이 메모리에 존재하지 않은 페이지에 있으므로 페이지 폴트를 발생시킨다.
    - 페이지가 적재되고 나면 프로세스는 수행을 계속하는데 프로세스가 사용하는 모든 페이지가 메모리에 올라올 때까지 필요할 때마다 페이지 폴트가 발생한다.
    - 필요한 모든 페이지가 적재되고 나면, 더 폴트가 발생하지는 않는다.

</br>

→ **순수 요구 페이징(pure demand paging)**

- 즉, **어떤 페이지가 필요해지기 전에는 결코 그 페이지를 메모리로 적재하지 않는 방법**이다.

</br>

> **요구 페이징을 지원하기 위해 필요한 하드웨어는 페이징과 스와핑을 위한 하드웨어와 동일하다.**

- **페이지 테이블**
    - 보호 비트들을 특별한 값, 또는 유효, 무효 비트를 통해 특정 항목을 무효로 설정할 수 있어야 한다.

</br>

- **보조 저장장치**
    - 메인 메모리에 없는 모든 페이지를 가지고 있다.
    - 보통은 고성능의 디스크, 또는 NVM이다.
    - **스왑 장치**라고도 하며, 이 목적을 위해 사용하는 저장장치 영역을 **스왑 공간**이라고 한다.

</br>

> **요구 페이징을 위한 필수적인 요구 사항은 페이지 폴트 오류 처리 후에 명령어 처리를 다시 시작할 수 있어야 한다는 것이다!**

- 페이지 폴트가 발생하여 중단된 프로세스 상태를 보관해 두면, 다시 이 프로세스를 시작할 때 해당 페이지가 메모리로 올라와서 접근 가능하다는 것 이외에는 정확히 같은 위치, 같은 상태에서 프로세스를 다시 수행할 수 있다.

</br>

> **한 명령어가 많은 기억 장소를 변경하는 것일 때는 상당히 어려운 문제가 발생한다.**

- 어느 블록이라도 페이지 경계에서 양쪽에 걸쳐 있으면 이동이 다 끝나지도 않은 상태에서 페이지 폴트가 발생할 수 있다.
    - 원천 블록과 목적 블록이 서로 겹쳐져 있는 경우에는, 단순히 명령어를 다시 실행하는 것만으로는 문제가 해결되지 않는다.

</br>

> **위와 같은 문제는 두 가지 방법으로 해결할 수 있다.**

1. 마이크로코드(microcode)로 양 블록의 두 끝을 계산하여 겹치지 않는 것을 확인한 후에, 접근을 시도한다.
2. 이동에 의해서 이전의 내용이 지워질 기억 장소들의 값을 보존하기 위해 임시 레지스터들을 사용한다.

</br>

### 가용 프레임 리스트

→ ***페이지 폴트를 해결하기 위해 대부분의 운영체제는 가용 프레임의 풀인 가용 프레임 리스트를 유지한다.***

<img width="388" alt="image" src="https://user-images.githubusercontent.com/106216912/221364564-2d695b89-655b-4e9f-ba84-ee7b5d876d28.png">

- 운영체제는 일반적으로 **zero-fill-on-demand**라는 기법을 사용해서 가용 프레임을 할당한다.
    - **이 프레임은 할당되기 전에 0으로 모두 채워져서 이전 내용이 지워진다.**

</br>

> **시스템이 시작되면 모든 가용 메모리가 가용 프레임 리스트에 넣어진다.**

- 가용 프레임이 요청되면, 가용 프레임 리스트의 크기가 줄어든다.

</br>

### 요구 페이징의 성능

→ ***요구 페이징은 컴퓨터 시스템의 성능에 큰 영향을 줄 수 있다.***

- **실질 접근 시간(effective access time : EAT)**
    - `p` = 페이지 폴트 확률
    - `ma` = 기억 장소 접근 시간
    - 실질 접근 시간 = `(1 - p) x ma + p x (페이지 폴트 시간)`

</br>

> **실제 접근 시간은 페이지 폴트율(page fault rate)에 비례한다.**

- ex) 1000번 중에 한 번의 접근에 페이지 폴트가 발생한다고 하면, 실제 접근 시간은 8.2마이크로초이다.
    - **컴퓨터는 요구 페이징 때문에 40배나 느려진다!**

</br>

- 만약 성능 저하를 10% 이하로 낮추고 싶다면, 다음 조건이 필요하다.

<img width="239" alt="image" src="https://user-images.githubusercontent.com/106216912/221364598-ef2d9950-b9f7-4d2b-80dc-b36e4a75cd44.png">

</br>

→ **요구 페이징 시스템에서 페이지 폴트 비율을 낮게 유지시키는 것은 상당히 중요하다!**

- **그렇지 않으면 실질 접근 시간이 커지고, 프로세스 수행은 심각하게 늦어진다.**

</br>

> **요구 페이징의 또 다른 특성 중 하나는 스왑 공간의 관리이다.**

- 스왑 공간에서의 디스크 입출력은 일반적으로 파일시스템의 입출력보다 빠르다.
    - 스왑 공간은 파일 시스템보다 더 큰 블록을 사용하고, 파일 찾기나 간접 할당 방법 등은 사용하지 않기 때문이다.

</br>

- **시스템이 더 나은 페이징 처리량을 얻는 옵션**
    1. 프로세스 시작 시 전체 파일 이미지를 스왑 공간에 복사한 다음, 스왑 공간에서 요구 페이징을 수행한다.
    - 단점 : 프로그램 시작 시 파일 이미지를 복사하는 것
    2. 프로그램을 처음 시작시킬 때는 파일 시스템으로부터 요구 페이징을 처리하지만, 그 페이지들이 교체될 때는 스왑 공간에 페이지를 기록한다.

</br>

> **어떤 시스템들은 실행 파일을 스왑 공간에 넣지 않음으로써 스왑 공간의 크기를 줄인다.**

- 실행 파일로부터 요구 페이지를 요청하면, 파일 시스템으로부터 그 페이지를 직접 가져온다.
    - 이 페이지들의 교체가 필요하면 이들 페이지에 새 페이지의 내용을 그대로 덮어쓸 수 있다.

</br>

- 그러나 스왑 공간은 여전히 파일과 관련이 없는 페이지 때문에 필요하다!
    - 이러한 메모리를 **익명(anonymous) 메모리**라고 한다.
        - 프로세스의 스택 및 힙이 포함된다.

</br>

> **모바일 운영체제는 통상 스와핑을 지원하지 않는다.**

- 대신 파일 시스템으로부터 요구 페이징을 하고 메모리가 부족하게 되면 응용으로부터 코드와 같은 읽기 전용 페이지들을 방출한다.

---

## 3. 쓰기 시 복사

→ ***`fork()` 시스템 콜을 통해 프로세스를 생성할 때 첫 요구 페이징조차 생략이 가능하다.***

- 이 기법을 통해 **프로세스 생성 시간을 더 줄일 수 있고, 새로 생성된 프로세스에 새롭게 할당되어야 하는 페이지의 수도 최소화**할 수 있다.

</br>

> **부모의 페이지들을 다 복사해오는 대신, 쓰기 시 복사(copy-on-write)방식을 사용할 수 있다!**

- 이 방식에서는 **자식 프로세스가 시작할 때 부모의 페이지를 당분간 함께 사용하도록** 한다.
    - 이 때 공유되는 페이지를 **쓰기 시 복사 페이지**라고 표시한다.
    - **둘 중 한 프로세스가 공유 중인 페이지에 쓸 때, 그 페이지의 복사본이 만들어진다.**

</br>

- `프로세스 1` 이 `페이지 C` 를 수정하기 전

<img width="489" alt="image" src="https://user-images.githubusercontent.com/106216912/221365583-a4895e82-ba07-434b-a406-7159f0f84e47.png">

</br>

- `프로세스 1` 이 `페이지 C` 를 수정한 후

<img width="483" alt="image" src="https://user-images.githubusercontent.com/106216912/221365596-97d9dbd8-5cc8-4201-b6bf-1c8d3e221490.png">

</br>

> **몇 가지 UNIX 변종들은 `vfork()` : virtual memory fork라는 시스템 콜을 제공한다.**

- `vfork()` 는 쓰기 시 복사 측면에서 `fork()` 와 다르게 동작한다.
    - `vfork()` 를 하면 부모 프로세스는 보류되고, 자식이 부모의 주소 공간을 사용하게 된다.
    - `vfork()` 는 쓰기 시 복사를 사용하지 않으므로, 자식이 주소 공간의 페이지를 수정하게 되면 변경된 페이지가 재실행 시 부모 프로세스에 그대로 보인다.

</br>

→ 페이지가 전혀 복사되지 않으므로, `vfork()` 는 매우 효율적이며, shell 구현 시에도 사용된다!

---

## 4. 페이지 교체

→ ***다중 프로그래밍 정도를 더 올리면, 메모리 과할당(over-allocation)이 발생한다.***

- 10개 페이지 중에서 5개만을 사용하는 6개의 프로세스를 실행시키면, 10개의 프레임은 남겨 놓고도 높은 **CPU 활용률과 처리율(throughput)** 을 얻을 수 있다.

</br>

> **시스템 메모리는 프로그램 페이지를 저장하는 용도로만 사용되는 것이 아니다.**

- I/O를 위한 버퍼도 상당한 양의 메모리를 사용하고, 이는 메모리 할당 알고리즘의 부담을 증가시킨다.
    - 얼마만큼의 메모리를 I/O 용도로 할당하고, 얼마만큼의 메모리는 프로그램에 할당하는가 하는 것은 매우 중요한 문제이다.

</br>

> **메모리의 초과 할당은 다음과 같이 나타난다.**

<img width="544" alt="image" src="https://user-images.githubusercontent.com/106216912/221371520-f693bb65-ceb5-46ff-8f5e-c1046085c56c.png">

- 프로세스가 실행되는 동안 **페이지 폴트**가 발생한다.
    - 운영체제는 필요로 하는 페이지가 보조저장장치에 저장된 위치를 알아내지만, 가용한 프레임 목록에 가용한 프레임이 없음을 발견한다.
        - 즉, 모든 메모리가 사용중이다.

</br>

> **이 시점에서 운영체제는 몇 가지 선택을 할 수 있다.**

- 프로세스를 종료할 수 있다.
    - 그러나 요구 페이징은 시스템의 활용률과 처리율을 올리기 위해 운영체제가 선택한 방법이다.
    - **사용자가 그들의 프로세스가 페이징 시스템에서 실행되고 있음을 알게 해서는 안 된다!**

</br>

- 대신, **운영체제는 표준 스와핑을 사용해서 프로세스를 스왑아웃 하여 모든 프레임을 비우고 다중 프로그래밍 정도를 줄일 수 있다.**
    - 하지만, **메모리와 스왑 공간 사이에 전체 프로세스를 복사하는 오버헤드로 인해 대부분의 운영체제에서 표준 스와핑이 더는 적용되지 않는다.**

</br>

→ ***대부분의 운영체제는 페이지 스와핑과 페이지 교체를 결합한다!***

</br>

### 기본적인 페이지 교체

→ ***페이지 교체는 다음과 같이 행해진다.***

- 만약 빈 프레임이 없다면 현재 사용되고 있지 않는 프레임을 찾아서 그것을 비워버린다.
    - 그 프레임의 내용을 스왑 공간에 쓰고, 그 페이지가 메모리에 이제는 존재하지 않는다는 것을 나타내기 위해 페이지 테이블을 변화시킴으로써 프레임을 비어있게 한다.
    - 이제 비워진 프레임을 페이지 폴트를 발생시킨 프로세스에서 사용할 수 있게 된다.

</br>

> **페이지 폴트 서비스 루틴은 페이지 교체를 포함하여 다음과 같이 수정되어야 한다.**

<img width="484" alt="image" src="https://user-images.githubusercontent.com/106216912/221371556-7fb4fbdf-87a7-4710-9185-31f5a55d56e3.png">

1. 보조저장장치에서 필요한 페이지의 위치를 알아낸다.
2. 빈 페이지 프레임을 찾는다.
    1. 비어 있는 프레임이 있다면 그것을 사용한다.
    2. 비어 있는 프레임이 없다면 **희생될(victim) 프레임**을 선정하기 위해 페이지 교체 알고리즘을 가동시킨다.
    3. 희생될 페이지를 보조저장장치에 기록하고, 관련 테이블을 수정한다.
3. 빼앗은 프레임에 새 페이지를 읽어오고, 테이블을 수정한다.
4. 페이지 폴트가 발생한 지점에서부터 프로세스를 계속한다.

</br>

> **페이지 교체는 요구 페이징의 기본이다.**

→ ***이를 통해 논리적 메모리와 물리 메모리 간의 분리가 완성된다.***

- 이 기법을 통해 **매우 작은 물리 메모리로도 프로그래머에게 광대한 가상 메모리를 제공**할 수 있다.
    - 요구 페이징을 하지 않더라도 논리 주소가 물리 주소로 사상되어 서로 다른 주소 집합을 가질 수 있지만, 프로세스의 모든 페이지는 물리 메모리에 존재해야만 한다.

</br>

- **요구 페이징은 논리 주소 공간의 크기가 물리 메모리에 의한 제약에서 벗어나도록 해 준다.**
    - 교체되려는 페이지가 변경된 경우에는, 디스크에 복사된다.
        - 나중에 이 페이지를 참조하게 되면 페이지 폴트가 발생한다.

</br>

> **요구 페이징 시스템은 두 가지 중요한 문제를 해결해야 한다.**

1. **프레임 할당 알고리즘**
2. **페이지 교체 알고리즘**

</br>

→ **즉, 여러 프로세스가 존재하는 경우 각 프로세스에 얼마나 많은 프레임을 할당해야 할지 결정해야 한다.**

- 일반적으로는 **페이지 폴트율이 가장 낮은 알고리즘**을 선정한다.

</br>

> **페이지 교체 알고리즘의 성능은 특정 메모리 참조 나열에 대해 알고리즘을 적용하여 페이지 폴트 발생 횟수를 계산하여 평가한다.**

→ ***이러한 메모리 주소의 나열을 참조열(reference string)이라고 부른다.***

- 참조열은 인공적으로 생성할 수도 있고, 주어진 시스템을 추적하여 매 메모리 참조 시의 주소를 기록할 수도 있다.

</br>

> **특정 프로세스의 참조 주소 추적 예시**

<img width="486" alt="image" src="https://user-images.githubusercontent.com/106216912/221371630-cd84c403-ab9e-4a84-887a-59c6a4b6d96b.png">

</br>

- 페이지 크기가 100바이트라면, 이 열은 다음과 같은 참조열로 줄일 수 있다.

<img width="244" alt="image" src="https://user-images.githubusercontent.com/106216912/221371645-9d1c0446-08ae-4df7-aa58-08d67ccc3d73.png">

</br>

> **일반 적으로 가용 페이지 프레임 수와 페이지 폴트율은 다음과 같은 상관관계를 나타낸다.**

<img width="482" alt="image" src="https://user-images.githubusercontent.com/106216912/221371664-1ebdf704-8bfc-43a2-9303-0f116807ed0d.png">

- **프레임의 수가 증가함에 따라 페이지 폴트 수는 어떤 최솟값으로 떨어진다.**
    - 물리 메모리를 추가하면, 프레임의 수가 증가한다.

</br>

→ 이제부터 페이지 교체 알고리즘을 설명하기 위해 3개의 프레임을 가진 메모리를 가정하고, 페이지 참조열은 다음과 같다고 가정한다.

<img width="440" alt="image" src="https://user-images.githubusercontent.com/106216912/221371685-0ff646cc-9c65-499b-ba72-27b93e9554d1.png">

</br>

### FIFO 페이지 교체

→ ***가장 간단한 페이지 교체 알고리즘은 FIFO(first-in first-out) 알고리즘이다.***

- FIFO 교체 알고리즘은 **어떤 페이지를 교체해야 할 때, 메모리에 올라온 지 가장 오래된 페이지를 선택**한다.
    - **큐의 머리 부분 페이지를 교체하고, 새로 올라온 페이지는 큐의 끝에 삽입하면 된다.**

</br>

- **페이지 폴트  : 15개**

<img width="579" alt="image" src="https://user-images.githubusercontent.com/106216912/221371717-5b7b5c81-3f32-42e6-a724-5bc66807f82a.png">

</br>

> **FIFO 페이지 교체 알고리즘은 이해하기도 쉽고, 프로그램하기도 쉽다.**

- **하지만 성능이 항상 좋지는 않다!**
    - 교체된 페이지가 오래전 사용된 뒤 더는 사용되지 않았던 초기화 모듈일 수도 있다.
    - **반대로, 교체된 페이지가 초기화된 뒤 계속해서 자주 사용되는 변수를 포함하고 있을 수도 있다.**

</br>

- 활발하게 사용되는 페이지를 교체한 뒤 거의 즉시 그 페이지를 다시 적재하기 위해 페이지 폴트가 발생한다.
    - 이 페이지를 위해 다른 페이지가 교체될 것이다.

</br>

→ **이처럼 잘못된 교체 결정은 페이지 폴트율을 높이고, 프로세스 실행 속도를 떨어뜨린다.**

</br>

> **Belady의 모순(Belady’s anomaly)**

<img width="486" alt="image" src="https://user-images.githubusercontent.com/106216912/221371754-0121cfcb-5d8c-4f9b-80ac-758cd22397d6.png">

- **프로세스에 프레임을 더 주었는데, 오히려 페이지 폴트율은 더 증가하는 현상**이 발생한다.

</br>

### 최적 페이지 교체

→ ***최적 교체 정책은 모든 알고리즘 보다 낮은 페이지 폴트율을 보이며, Belady의 모순이 발생하지 않는다.***

- **앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체한다!**
    - 이 알고리즘은 할당된 프레임 수가 고정된 경우 **가장 낮은 페이지 폴트율**을 보장한다.

</br>

- **페이지 폴트 : 9개**

<img width="576" alt="image" src="https://user-images.githubusercontent.com/106216912/221372253-d44a68ea-d833-4103-83ce-dbe5f162783e.png">

</br>

> **하지만, 이 알고리즘의 실제 구현은 어렵다!**

→ ***이 방식은 프로세스가 앞으로 메모리를 어떻게 참조할 것인지를 미리 알아야 한다.***

- 따라서, 최적 페이지 교체 알고리즘은 주로 비교 연구 목적을 위해서 사용된다.

</br>

### LRU 페이지 교체

→ ***최적 알고리즘이 불가하다면, 최적 알고리즘의 근사 알고리즘은 가능하다.***

- 최근의 과거를 가까운 미래의 근사치로 본다면, 가장 오랜 기간 사용되지 않은 페이지를 교체할 수 있다!
    - **least-recently-used(LRU) 알고리즘**

</br>

> **LRU 알고리즘은 페이지마다 마지막 사용 시간을 유지한다.**

- **페이지 교체 시에 LRU는 가장 오랫동안 사용되지 않은 페이지를 선택한다.**
    - 이 정책은 미래 대신 과거 시간에 대해 적용한 최적 교체 정책으로 생각할 수 있다.

</br>

- **페이지 폴트 : 12개**

<img width="578" alt="image" src="https://user-images.githubusercontent.com/106216912/221372297-5628ee7a-99c4-4aff-b695-9ffc7c49f639.png">

</br>

> **LRU 정책은 페이지 교체 알고리즘으로 자주 사용되며, 좋은 알고리즘으로 인정받는다.**

→ ***문제는 어떻게 이 알고리즘을 구현하냐! 하는 것이다.***

- LRU 페이지 교체 알고리즘은 **하드웨어의 지원**이 필요하다.
    - 프레임들을 최근 사용된 시간 순서로 파악할 수 있어야 한다.

</br>

> **두 가지의 구현 방법이 가능하다.**

1. **계수기(counters)**

<img width="534" alt="image" src="https://user-images.githubusercontent.com/106216912/221372387-02285172-bee9-4c98-9db5-7c988b3771c9.png">

- 가장 간단한 방법으로, **각 페이지 항목마다 사용 시간 필드를 넣고 CPU에 논리적인 시계나 계수기를 추가**한다.
    - 메모리가 접근될 때마다 시간은 증가한다.
    - 페이지에 대한 참조가 일어날 때마다 페이지의 사용 시간 필드에 시간 레지스터의 내용이 복사된다.
        - 이렇게 각 페이지의 마지막 참조 시간을 유지할 수 있다.
        - 시간 값이 가장 작은 페이지가 교체된다.

</br>

2. **스택(stack)**

<img width="387" alt="image" src="https://user-images.githubusercontent.com/106216912/221372406-096ab786-dc45-477b-b895-4c9bd90de3f8.png">

- **페이지 번호의 스택을 유지하는 방법**이다.
    - 페이지가 참조될 때마다 페이지 번호는 스택 중간에서 제거되어 스택 꼭대기(top)에 놓이게 된다.
    - 이렇게 하면 스택의 꼭대기는 항상 가장 최근에 사용된 페이지이고, 밑바닥(bottom)은 가장 오랫동안 이용되지 않은 페이지이다.
        - 스택의 중간에서 항목을 제거해야 할 필요가 있으므로, 스택은 보통 이중 연결 리스트로 구현한다.

</br>

> **최적 교체와 마찬가지로, LRU 교체는 Belady의 모순 현상을 야기하지 않는다!**

- Belady의 모순 현상을 나타내지 않는 페이지 교체 알고리즘을 **스택 알고리즘**이라고 부른다.
    - 스택 알고리즘은 `n` 개의 프레임에 수록되는 페이지의 집합이 항상 `n+1` 개의 프레임에 수록되는 페이지 집합의 부분집합이 되는 알고리즘이다.

</br>

> **양쪽 LRU 구현 방법 모두 반드시 표준적인 TLB 레지스터 이상의 하드웨어 지원이 필요하다.**

- **계수기 값과 스택을 갱신하는 일이 메모리 참조 때마다 수행**되어야 한다.
    - 이러한 작업을 소프트웨어로 하기 위해 인터럽트를 사용한다면, 최소 10배 이상 메모리 참조 속도가 느려지고, 결국 모든 프로세스의 실행 속도를 그만큼 저하하게 된다.

</br>

### LRU 근사 페이지 교체

→ ***LRU 페이지 교체 지원을 충분히 할 수 있는 하드웨어는 많지 않다.***

- 어떤 시스템에서는 전혀 하드웨어적인 지원을 하지 않고, 다른 알고리즘을 쓸 수밖에 없다.
    - 하지만, 많은 시스템은 **참조 비트(reference bit)** 의 형태로 어느 정도의 지원은 하고 있다!
        - **페이지 참조가 있을 때마다 하드웨어가 그 페이지에 대한 참조 비트를 설정한다.**

</br>

→ 처음에 모든 참조 비트는 운영체제에 의해 `0` 으로 채워지고, 프로세스가 실행되면서 참조되는 페이지의 비트는 하드웨어가 `1` 로 세팅한다.

</br>

> **부가적 참조 비트 알고리즘**

→ ***일정한 간격마다 참조 비트들을 기록함으로써 추가적인 선후 관계 정보를 얻을 수 있다.***

<img width="190" alt="image" src="https://user-images.githubusercontent.com/106216912/221372437-98ce723b-d403-4d00-adde-5c595c691d70.png">

- 각 페이지에 대해 8비트의 참조 비트를 할당한다.
- 타이머 인터럽트가 제어를 운영체제에 넘기면, **참조 비트를 8비트의 높은 자리로 이동하고 다른 비트들을 하나씩 오른쪽으로 이동**한다.
    - 그 후, 가장 낮은 번호를 가진 페이지를 대치한다.

</br>

> **2차 기회 알고리즘**

→ ***2차 기회 알고리즘의 기본은 FIFO 교체 알고리즘이다.***

- 하지만, **페이지가 선택될 때마다 참조 비트를 확인**한다.
    - 참조 비트가 `0` 이면 페이지를 교체하고, `1` 이면 다시 한번 기회를 주고 다음 FIFO 페이지로 넘어간다.
    - 한 번 기회를 받게 되면 참조 비트는 해제되고, 도착 시간이 현재 시간으로 재설정된다.
        - 이에 따라, 그 페이지는 다른 모든 페이지가 교체될 때까지 교체되지 않는다.

</br>

→ **따라서, 참조 비트가 계속 설정되어 있을 정도로 자주 사용되는 페이지는 전혀 교체되지 않는다!**

</br>

> **2차 기회 알고리즘을 구현하는 방법은 순환 큐(circular queue)를 이용하는 것이다.**

<img width="480" alt="image" src="https://user-images.githubusercontent.com/106216912/221372457-232c096b-6a47-463f-a790-dc6e76ba08f9.png">

- 이 큐에는 포인터가 있어서 다음에 교체될 페이지를 가리킨다.
    - 어떤 프레임을 빼앗아야 할 일이 필요해지면, 포인터는 `0` 값의 참조 비트를 가진 페이지를 발견할 때까지 큐를 뒤진다.
    - 포인터가 돌아가면서 참조 비트 값들이 `1` 인 것은 `0` 으로 바꾼다.
    - 희생될 페이지가 발견되면, 그 페이지는 교체되고 새로운 페이지는 순환 큐의 해당 위치에 삽입한다.

</br>

> **개선된 2차 기회 알고리즘**

→ ***2차 기회 알고리즘은 참조 비트와 변경 비트를 사용하면 더 개선할 수 있다.***

</br>

> **두 개의 비트를 조합해서 사용하면 다음 네 가지의 등급이 가능하다.**

1. (0, 0) 최근에 사용되지도, 변경되지도 않은 경우 → 교체하기 가장 좋은 페이지
2. (0, 1) 최근에 사용되지는 않았지만, 변경은 된 경우 → 이 페이지는 뺏어 오려면 디스크에 내용을 기록해야 하므로 적절하지 않다.
3. (1, 0) 최근에 사용은 되었으나, 변경은 되지 않은 경우 → 이 페이지는 곧 다시 사용될 가능성이 높다.
4. (1, 1) 최근에 사용도 되었고, 변경도 된 경우 → 아마 곧 다시 사용될 것이며 뺏으려면 디스크에 그 내용을 먼저 기록해야 한다.

</br>

→ **페이지 교체가 필요할 때 클록 알고리즘과 같은 방법을 사용하되, 참조 비트를 확인하는 것이 아닌 페이지가 어떤 등급에 속하는지 확인한다.**

</br>

### 계수-기반 페이지 교체

→ ***페이지 교체를 위해 사용되는 많은 다른 알고리즘이 있다.***

</br>

> **각 페이지를 참조할 때마다 계수를 하여 다음과 같은 두 가지의 기법을 만들 수 있다.**

- **LFU(least frequently used) 알고리즘**
    - **참조 횟수가 가장 작은 페이지를 교체하는 방법이다.**
    - 활발하게 사용되는 페이지는 큰 참조 횟수 값을 갖게 될거라고 생각한다.
    - 어떤 프로세스가 초기 단계에서는 한 페이지를 집중적으로 많이 사용하지만, 그 후로 다시는 이 페이지를 사용하지 않는 경우에는 판단이 빗나갈 수 있다.
        - 해결책 : 참조 횟수를 일정한 시간마다 하나씩 오른쪽으로 시프트 해서 지수적으로 그 영향력을 감소시킨다.

</br>

- **MFU(most frequently used) 알고리즘**
    - **가장 작은 참조 회수를 가진 페이지가 가장 최근 참조된 것이고, 앞으로 사용될 것이라는 판단을 한다.**

</br>

→ **이 두 알고리즘은 일반적으로 잘 쓰이지 않는다.**

- 구현하는데 상당히 비용이 많이 들고, 최적 페이지 교체 정책을 제대로 근사하지 못하기 때문이다.

</br>

### 페이지-버퍼링 알고리즘

→ ***페이지 교체 알고리즘과 병행하여 여러 가지 버퍼링 기법이 사용될 수 있다.***

1. **시스템들이 가용 프레임 여러 개를 풀(pool)로 갖고 있다가, 페이지 폴트가 발생하면 교체될 페이지를 찾지만 교체될 페이지의 내용을 디스크에 기록하기 전에 가용 프레임에 새로운 페이지를 먼저 읽어 들이는 방법**
    - 이 방법은 교체될 페이지가 쓰이기를 기다리지 않고, 프로세스가 가능한 한 빨리 시작할 수 있도록 해준다.
    - 이후에 교체될 페이지가 다 쓰이고 나면 그 프레임이 가용 프레임 풀에 추가된다.

</br>

2. **변경된 페이지 리스트를 유지하는 방법**
    - 페이징 장치가 아무런 일도 없게 되면, 그때마다 변경된 페이지들을 차례로 보조저장장치에 쓴 후에, 페이지의 변경 비트를 `0` 으로 되돌려 놓는다.
        - 이렇게 하면 나중에 페이지가 실제로 교체될 때 변경되지 않은 상태여서, 쓰기 작업이 불필요할 가능성이 높아진다.

</br>

### 응용(applications)과 페이지 교체

→ ***몇명 운영체제는 특별한 프로그램들에는 보조저장장치 파티션을 파일 시스템 구조가 아닌, 단순한 논리적인 블록들의 순차적인 배열로서 사용할 수 있게 해주는 기능을 갖추고 있다.***

- 이 배열은 raw disk라고 불리고, 이에 대한 I/O는 **raw I/O**라는 용어를 사용한다.
    - raw I/O는 파일 시스템의 요구 페이징, 파일 잠금, 선반입, 공간 할당, 디렉터리, 파일 이름 등의 모든 파일 시스템 서비스를 거치지 않는다.

---