## 1. 배경

→ ***메인 메모리는 현대 컴퓨터 시스템의 운영에 중심적인 역할을 한다.***

- 메모리는 각각 주소가 할당된 일련의 바이트들로 구성된다.
    - CPU는 PC(Program Counter)가 지시하는 대로 메모리로부터 다음 수행할 명령어를 가져온다.
        - 그 명령어는 필요한 경우 추가적인 데이터를 가져올 수도 있고, 데이터를 메모리에서 내보낼 수도 있다.

</br>

- 전형적인 명령어 실행은 메모리로부터 한 명령어를 가져오는 데서부터 시작된다.
    - 그 후 명령어를 해독하고, 메모리에서 피연산자(operand)를 가져와 피연산자에 대해 명령어를 실행한다.
    - 그리고 계산 결과를 메모리에 다시 저장한다.

</br>

→ **메모리는 주소에 지시한 대로 읽기, 쓰기만 할 뿐 이 주소들이 어떻게 생성되었는지, 그 주소가 가리키는 내용이 무엇인지는 모른다!**

</br>

### 기본 하드웨어

→ ***메인 메모리와 각 처리 코어에 내장된 레지스터들은 CPU가 직접 접근할 수 있는 유일한 범용 저장장치이다.***

- 기계 명령어들은 메모리 주소만을 인수로 취하고, 디스크의 주소를 인수로 취하지 않는다.
    - 따라서 모든 실행되는 명령어와 데이터들은 CPU가 직접적으로 접근할 수 있는 메인 메모리와 레지스터에 있어야 한다.
        - 만약 데이터가 메모리에 없다면, CPU가 처리하기 전에 메모리에 이동시켜야 한다.

</br>

> **메인 메모리의 접근을 완료하기 위해서는 많은 CPU 클록 틱 사이클이 소요된다.**

- 이 경우, CPU가 필요한 데이터가 없어서 명령어를 수행하지 못하고 지연되는(stall) 현상이 발생하게 된다.
    - 해결 방법 : CPU와 메인 메모리 사이에 빠른 속도의 **캐시 메모리**를 추가하는 것
        - CPU에 구축된 캐시를 관리하여 하드웨어는 어떠한 운영체제의 도움 없이 메모리 접근 속도를 향상한다.

</br>

> **물리 메모리의 상대적인 접근 속도의 차이를 고려하는 것에 추가로 올바른 동작을 보장해야만 한다.**

- 시스템이 올바르게 동작하기 위해서는 사용자 프로그램으로부터 운영체제 영역을 보호하고, 사용자 프로그램 사이도 서로 보호해야 한다.
    - 운영체제가 CPU와 메모리 간의 접근 중에 개입하게 되면 성능이 떨어지기 때문에, 보호 기법은 반드시 하드웨어가 지원해야 한다.

</br>

> **먼저, 각각의 프로세스가 독립된 메모리 공간을 가지도록 보장해야 한다.**

- 개별적인 프로세스별 메모리 공간은 서로를 보호하고, 병행 실행을 위해 여러 프로세스가 메모리에 적재되게 하는 것이 필수적이다.
    - 개별적인 메모리 공간을 분리하기 위해, **특정 프로세스만 접근할 수 있는 합법적인 메모리 주소 영역을 설정하고, 합법적인 영역만 접근하도록 하는 것**이 필요하다.

</br>

<img width="295" alt="image" src="https://user-images.githubusercontent.com/106216912/221346230-25764e99-5f46-47c1-a1ff-1d4c42a06e24.png">

- **기준(base)와 상한(limit)라고 불리는 두 개의 레지스터를 사용해서 보호 기법을 제공**한다.
    - **기준 레지스터** : 가장 작은 합법적인 물리 메모리 주소의 값을 저장
    - **상한 레지스터** : 주어진 영역의 크기를 저장

</br>

<img width="383" alt="image" src="https://user-images.githubusercontent.com/106216912/221346264-f21aa07b-cd92-4b03-89f5-f7232d641e89.png">

- 메모리 공간의 보호는 CPU 하드웨어가 사용자 모드에서 만들어진 모든 주소와 레지스터를 비교함으로써 이루어진다.
    - 사용자 모드에서 수행되는 프로그램이 **운영체제의 메모리 공간이나, 다른 사용자 프로그램의 메모리 공간에 접근하면 운영체제는 치명적인 오류로 간주하고, 트랩(trap)을 발생**시킨다.

</br>

→ **이러한 기법은 사용자 프로그램이 운영체제나 다른 사용자 프로그램의 코드나 데이터 구조를 수정하는 것을 막는다.**

</br>

> **기준과 상한 레지스터는 여러 가지 특권 명령을 사용하는 운영체제에 의해서만 적재(load)된다.**

- 특권 명령은 오직 커널 모드에서만 수행되고, 운영체제만 커널 모드에서 수행되기 때문이다.
    - 운영체제만 레지스터들의 값을 변경할 수 있도록 허가하여, 사용자 프로그램이 레지스터의 내용을 변경하는 것을 막는다.

</br>

> **커널 모드에서 수행되는 운영체제는 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 어떠한 제약도 받지 않는다.**

- 따라서, 운영체제는 사용자 프로그램을 사용자 메모리 영역에 적재한다.
    - 그 후, 오류가 발생한 경우에 그 프로그램을 덤프(dump out), 시스템 콜의 매개 변수를 변경, 사용자 메모리로부터의 입출력과 다른 많은 서비스를 제공할 수 있다.

</br>

### 주소의 할당

→ ***프로그램은 원래 이진 실행 파일 형태로 디스크에 저장되어 있다.***

- 실행하려면 프로그램을 메모리로 가져와서 프로세스 문맥내에 배치해야 한다.

</br>

> **대부분의 시스템은 사용자 프로세스가 메모리 내 어느 부분으로도 올라올 수 있도록 지원한다.**

<img width="281" alt="image" src="https://user-images.githubusercontent.com/106216912/221346321-9085a559-bb4a-4e6d-9260-a93a91337222.png">

→ ***사용자 프로그램은 여러 단계를 거쳐 실행되기 때문에, 단계를 거치는 동안 주소들은 여러 다른 표현 방식을 거치게 된다.***

- 원시 프로그램에서 주소는 숫자가 아닌 **심볼 형태**로 표현된다.
    - 컴파일러는 이 심볼 주소를 **재배치 가능 주소**로 바인딩시킨다.
    - 그 후, 링커나 로더가 재배치 가능 주소를 **절대 주소**로 바인딩시킨다.

</br>

> **메모리 주소 공간에서 명령어와 데이터의 바인딩은 그 바인딩이 이루어지는 시점에 따라 구분된다.**
> 
- **컴파일 시간 바인딩**
    - **프로세스가 메모리 내에 들어갈 위치를 컴파일 시간에 미리 아는 경우**
    - 컴파일러는 절대 코드를 생성할 수 있다.

- **적재 시간 바인딩**
    - **프로세스가 메모리 내에 적재될 위치를 컴파일 시점에 알지 못하는 경우**
    - 컴파일러는 이진 코드를 재배치 가능 코드로 만들고, 최종 바인딩은 적재 시간까지 연기한다.

- **실행 시간 바인딩**
    - **프로세스가 실행하는 중간에 메모리 내의 한 세그먼트로부터 다른 세그먼트로 옮겨질 수 있는 경우**
    - 바인딩을 실행 시간까지 연기한다.

</br>

### 논리 대 물리 주소 공간

- **논리 주소(logical address)** : CPU가 생성하는 주소
- **물리 주소(physical address)** : 메모리가 취급하게 되는 주소

</br>

> **컴파일, 또는 적재 시에 주소를 바인딩 하면 논리 주소와 물리 주소가 같다.**

- 하지만, 실행 시간 바인딩 기법에서는 논리, 물리 주소가 다르다!
    - 이 때는 논리 주소를 **가상 주소(virtual address)** 라고 한다.
    - 논리 주소 = 가상 주소

</br>

<img width="429" alt="image" src="https://user-images.githubusercontent.com/106216912/221346386-8b1fd6a6-fe22-4dd8-b068-972040143905.png">

- **메모리 관리 장치(MMU : memory management unit)**
    - **프로그램의 실행 중에 가장 주소를 물리 주소로 바꿔주는 변환 작업을 실행**한다.

</br>

> **여기서는 기준 레지스터 기법을 일반화시킨 아주 단순한 MMU 기법에 따른 변환을 설명한다.**

<img width="390" alt="image" src="https://user-images.githubusercontent.com/106216912/221346409-36b31f57-d1d0-4203-84d6-dbdee49ade45.png">

- 기준 레지스터 = **재배치(relocation) 레지스터**
    - 재배치 레지스터 속에 들어있는 값은, **주소가 메모리로 보내질 때마다 그 모든 주소에 더해진다.**
        - ex) 재배치 레지스터 값 = 14000, 프로세스가 346번지에 액세스하면, 사실은 메인 메모리에 14346번지에 액세스하게 되는 것

</br>

### 동적 적재

→ ***메모리 공간의 더 효율적 이용을 위해서는 동적 적재(dynamic loading)을 해야한다.***

- **동적 적재에서 각 루틴은 실제 호출되기 전까지는 메모리에 올라오지 않고, 재배치 가능한 상태로 디스크에서 대기**하고 있다.
    - 이 루틴이 다른 루틴을 호출하였는데 적재되어 있지 않다면, 재배치 가능 연결 적재기가 요구된 루틴을 메모리로 가져오고, 테이블에 기록한다.

</br>

> **동적 적재의 장점**

→ ***루틴이 필요한 경우에만 적재된다.***

- 오류 처리 루틴과 같은 아주 간혹 발생하면서도, 실행할 코드가 많은 경우에 특히 유용하다.

</br>

→ **동적 적재는 운영체제로부터 특별한 지원이 필요없다.**

- 사용자 자신이 프로그램의 설계를 책임져야 하고, 운영체제는 동적 적재를 구현하는 라이브러리 루틴을 제공한다.

</br>

### 동적 연결 및 공유 라이브러리

→ ***동적 연결 라이브러리(DLL)는 사용자 프로그램이 실행될 때, 사용자 프로그램에 연결되는 시스템 라이브러리이다.***

- **동적 연결에서는 연결이 실행 시기까지 미루어진다.**

</br>

> **DLL의 장점**

- **라이브러리를 여러 프로세스 간에 공유할 수 있다.**
    - 따라서, **메인 메모리에 DLL 인스턴스가 하나**만 있을 수 있다.
    - 라이브러리 루틴을 바꿀 때 유용하다.
    - DLL = **공유 라이브러리**

</br>

> **동적 적재와는 달리, 동적 연결과 공유 라이브러리는 일반적으로 운영체제의 도움이 필요하다.**

- 메모리에 있는 프로세스들이 각자의 공간은 자기만 액세스할 수 있도록 보호된다면, 운영체제만이 기억 공간에 루틴이 있는지를 검사해 줄 수 있다.
    - 또한, 운영체제만이 여러 프로세스가 같은 메모리 주소를 공용할 수 있도록 해줄 수 있다.

---

## 2. 연속 메모리 할당

→ ***메인 메모리는 운영체제 뿐만 아니라 여러 사용자 프로세스도 수용해야 한다.***

- 또한, 각 영역은 각각 목적에 맞도록 효율적으로 관리되어야 한다.

</br>

> **메모리는 일반적으로 두 개의 부분으로 나누어진다.**

- 운영체제를 위한 것, 그리고 사용자 프로세스를 위한 것
    - 많은 운영체제는 운영체제를 높은 메모리에 배치한다.

</br>

> **일반적으로 여러 사용자 프로세스가 동시에 메모리에 상주하기를 원한다.**

- 따라서, 메모리에 적재되기를 기다리는 프로세스에 사용 가능한 메모리를 할당하는 방법을 고려해야 한다.

</br>

### 메모리 보호

→ ***프로세스가 자신이 소유하지 않은 메모리를 접근할 수 없게 강제할 수 있다.***

<img width="441" alt="image" src="https://user-images.githubusercontent.com/106216912/221347883-33175a18-45f8-4e01-ba2e-934331613400.png">

- **재배치 레지스터** : 가장 작은 물리 주소의 값을 저장
- **상한 레지스터** : 논리 주소의 범위 값을 저장

</br>

→ **각각의 논리 주소는 상한 레지스터가 지정한 범위 안에 존재해야 한다!**

- MMU는 동적으로 논리 주소에 재배치 레지스터의 값을 더함으로써, 주소를 변환한다.
    - 변환된 주소는 메모리로 보내진다.

</br>

> **CPU 스케줄러가 다음으로 수행할 프로세스를 선택할 때, 디스패처는 문맥 교환의 일환으로 재배치 레지스터와 상한 레지스터에 정확한 값을 적재한다.**

- CPU에 의해 생성되는 모든 주소는 이 레지스터들의 값을 참조해서 확인 작업을 거친다.
    - 따라서, 우리는 운영체제와 다른 사용자 프로그램을 현재 수행 중인 사용자 프로그램의 접근으로부터 보호할 수 있다.

</br>

### 메모리 할당

→ ***메모리를 할당하는 가장 간단한 방법은, 프로세스를 메모리의 가변 크기 파티션에 할당하는 것이다.***

- 각 파티션에는 하나의 프로세스만 적재될 수 있다.
    - 가변 파티션 기법에서 운영체제는 사용 가능한 메모리 부분과 사용 중인 부분을 나타내는 테이블을 유지한다.

</br>

<img width="483" alt="image" src="https://user-images.githubusercontent.com/106216912/221347923-70f80699-2caa-433e-a959-3c25732fad72.png">

- 처음에는 모든 메모리가 사용자 프로세스에 사용 가능하고, 하나의 큰 사용 가능한 메모리 블록인 hole로 간주한다.
    - 프로세스가 시스템에 들어오면, 운영체제는 각 프로세스가 메모리를 얼마나 요구하는지, 사용 가능한 메모리 공간이 어디에 얼마나 있는지를 고려해서 공간을 할당한다.
        - 그 후, CPU를 할당받기 위해 경쟁한다.
        - 프로세스가 끝내면 메모리를 반납하고, 운영체제는 다른 프로세스에게 이 공간을 할당한다.

</br>

> **이러한 기법은 동적 메모리 할당 문제의 특별한 예시이다.**

- 일련의 가용 공간-리스트로부터 크기 `n` - 바이트 블록을 요구하는 것을 어떻게 만족시켜 줄 것이냐를 결정하는 문제이다.
    - 해결책은 여러 가지!

</br>

> **일반적인 기법의 종류**

- **최초 적합(first-fit)**
    - **첫 번째 사용 가능한 가용 공간을 할당한다.**

- **최적 적합(best-fit)**
    - **사용 가능한 공간 중에서 가장 작은 것을 택한다.**
    - 리스트가 크기 순으로 되어 있지 않다면 전 리스트를 검색해야만 한다.

- **최악 적합(worst-fit)**
    - **가장 큰 가용 공간을 택한다.**
    - 할당해 주고 남는 가용 공간은 충분히 커서, 다른 프로세스들을 위해 유용하게 사용될 수 있다.

</br>

→ ***최초 적합, 최적 적합 모두가 시간과 메모리 이용 효율 측면에서 최악 적합 보다는 좋다!***

- 최초 적합이 일반적으로 속도는 더 빠르다.

</br>

### 단편화

→ ***최초 적합, 최적 적합 모두 외부 단편화(external fragmentation)으로 인해 어려움을 겪는다.***

- 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 어떤 가용 공간은 너무 작은 조각이 되어 버린다.
- **외부 단편화** : **유휴 공간들을 모두 합치면 충분한 공간이 되지만, 그것들이 너무 작은 조각들로 여러 곳에 분산되어 있을 때 발생**한다.
    - **최악의 경우에는, 모든 프로세스 사이마다 못 쓰게 된 가용 공간을 가질 수 있다.**

</br>

> **메모리의 전체 크기와 프로세스 크기들은 모두 외부 단편화에 따라 큰 영향을 미칠 수 있다.**

- 최초 적합의 경우, `N` 개의 블록이 할당되었을 때 `0.5N` 개의 블록이 단편화 때문에 손실될 수 있다.
    - 50% 규칙

</br>

> **메모리 공간을 낭비하는 현상인 단편화는 내부적으로도 발생할 수 있다.**

- 일반적으로는 메모리를 먼저 아주 작은 공간들로 분할하고, 프로세스가 요청하면 할당을 항상 이 분할된 크기의 정수배로만 해주는 것이 보통이다.
    - 이들 두 크기 사이의 남는 부분이 바로 **내부 단편화**이다.

</br>

> **압축 : 외부 단편화 문제를 해결하는 방법**

→ **메모리의 모든 내용을 한 군데로 몰고, 모든 가용 공간을 다른 한 군데로 몰아서 큰 블록을 만든다.**

- 그러나 압축이 항상 가능한 것은 아니다.
    - **압축은 프로세스들의 재배치가 실행 시간에 동적으로 이루어지는 경우에만 가능**하다.

</br>

→ **외부 단편화 문제를 해결하는 다른 방법?**

- 한 프로세스의 논리 주소 공간을 여러 개의 비연속적인 공간으로 나누어 필요한 크기의 공간이 가용해지는 경우, 물리 메모리를 프로세스에 할당하는 방법
    - **페이징**에서 사용되는 방법이다.

---

## 3. 페이징

→ ***현재까지는 프로세스의 물리 공간이 연속적이여야만 했다.***

- 이제 프로세스의 물리 주소 공간이 연속되지 않아도 되는 메모리 관리 기법인 페이징을 알아본다.
    - 페이징은 외부 단편화와 관련 압축의 필요성을 피한다.

</br>

### 기본 방법

→ ***물리 메모리는 프레임(frame)이라는 같은 크기 블록으로 나누어지고, 논리 메모리는 페이지(page)라는 같은 크기의 블록으로 나누어진다.***

</br>

> **CPU에서 나오는 모든 주소는 페이지 번호(p)와 페이지 오프셋(d: offset)으로 나누어진다.**

<img width="519" alt="image" src="https://user-images.githubusercontent.com/106216912/221350690-9e5d65f1-e2de-4818-bfe7-104b18bf5bef.png">

</br>

<img width="384" alt="image" src="https://user-images.githubusercontent.com/106216912/221350705-82eb6b4d-080b-4f05-81be-572705f225cf.png">

- **페이지 번호** : 프로세스 페이지 테이블(page table)을 액세스할 때 사용
- **페이지 테이블** : 물리 메모리의 각 프레임의 시작 주소를 저장
- **오프셋** : 참조되는 프레임 안에서의 위치

</br>

→ **프레임의 시작 주소 + 페이지 오프셋 = 물리 메모리의 주소**

<img width="390" alt="image" src="https://user-images.githubusercontent.com/106216912/221350737-7244ad41-b082-4b0f-8027-b4a462bdad24.png">

</br>

> **CPU에 의해 생성된 논리 주소를 물리 주소로 변환하기 위해 MMU가 취한 단계**

1. 페이지 번호 `p` 를 추출하여 페이지 테이블의 인덱스로 사용한다.
2. 페이지 테이블에서 해당 프레임 번호 `f` 를 추출한다.
3. 논리 주소의 페이지 번호 `p` 를 프레임 번호 `f` 로 바꾼다.

</br>

> **페이징 자체는 일종의 동적 재배치이다.**

- 모든 논리 주소는 페이징 하드웨어에 의해 실제 주소로 바인딩 된다.
- 페이징을 사용하는 것은 각 메모리 프레임마다 하나씩 기준 레지스터를 테이블로 유지하는 것과 유사하다.

</br>

> **페이징 기법을 사용하면 외부 단편화가 발생하지 않는다!**

- 모든 놀고 있는 프레임이 프로세스에 할당될 수 있기 때문이다.
    - 하지만, **내부 단편화는 발생한다.**
        - 할당은 항상 프레임의 정수배로 할당되기 때문이다.
        - 프로세스가 페이지 경계와 일치하지 않는 크기의 메모리를 요구한다면, 마지막 페이지 프레임은 전부 할당되지 않는다.

</br>

→ 프로세스의 크기가 페이지 크기와 무관하다면, 평균적으로 프로세스 당 반 페이지 정도의 내부 단편화가 예상된다.

- **작은 페이지 크기가 바람직할 것 같지만, 페이지 크기가 작아지면 페이지 테이블의 크기는 커지고, 테이블이 차지하는 공간은 낭비**된다.
    - 디스크의 입장에서는 페이지의 크기가 클수록 효율적이다.

</br>

<img width="438" alt="image" src="https://user-images.githubusercontent.com/106216912/221350777-387716d2-258a-47b0-bd6b-d74597efc64d.png">

- 프로세스가 `n` 개 페이지를 요구하면, 메모리에서 이용할 수 있는 프레임이 `n` 개 있어야 한다.
    - `n` 개의 프레임을 사용할 수 있다면 이 프레임들은 이 프로세스에 할당한다.
        - 그 후, 프로세스의 처음 페이지가 할당된 프레임 중 하나에 적재되고, 그 프레임 번호가 페이지 테이블에 기록된다.
        - 그다음 페이지는 또 다른 프레임에 적재되고, 또 프레임 번호가 페이지 테이블에 기록되는 과정이 반복된다.

</br>

> **페이징의 가장 중요한 특징 : 메모리에 대한 프로그래머의 인식과 실제 내용이 서로 다르다!**

- 프로그래머는 메모리가 하나의 연속적인 공간이며, 메모리에는 이 프로그램만 있다고 생각한다.
    - 하지만 **실제로는 프로그램은 여러 곳에 프레임 단위로 분산되어 있고, 많은 다른 프로그램이 올라와 있다.**

</br>

> **운영체제는 물리 메모리를 관리하기 때문에 물리 메모리의 자세한 할당에 대해 파악하고 있어야 한다.**

- 어느 프레임이 할당되어 있고, 어느 프레임이 사용 가능한지, 총 프레임은 몇 개나 되는지 알아야 한다.
    - **프레임 테이블**이라는 시스템에 하나밖에 없는 자료구조에 존재한다.

</br>

> **운영체제는 모든 프로세스의 주소들을 실제 주소로 사상할 수 있어야 한다.**

- 사용자가 시스템 콜을 호출해서 인자로 어떤 주소를 주면, 제대로 사상해서 정확히 그 물리 주소를 찾아가야 한다.

</br>

### 하드웨어 지원

→ ***메인 메모리에 페이지 테이블을 저장하면 문맥 교환 속도가 빨라지지만, 메모리 액세스 시간은 느려진다.***

- 페이지 번호를 기준으로 페이지 테이블의 항목을 찾고, 실제 주소를 생성해서 메모리에서 원하는 위치에 액세스할 수 있다.
    - 이런 경우, **두 번의 메모리 액세스가 필요하다!**
        - **메모리 접근 시간은 2배로 느려지고, 대부분의 상황에서는 허용할 수 없는 지연 시간이다.**

</br>

> **문제의 해결에는 TLB(Translation Look-aside Buffers)라고 불리는 특수한 소형 하드웨어 캐시가 사용된다.**

- **TLB는 매우 빠른 연관 메모리로 구성**된다.
    - TLB 내의 각 항목은 **키(key)** 와 **값(value)** 로 구성된다.
    - 페이지를 찾아달라고 요청이 들어오면, 찾고자 하는 페이지를 동시에 여러 개의 내부 키와 비교한다.
        - 페이지 번호가 같은 것이 발견되면, 그에 대응하는 프레임 번호를 알려준다.

</br>

<img width="480" alt="image" src="https://user-images.githubusercontent.com/106216912/221350817-698d93bc-d1db-4b02-aa9b-7e900ab2f972.png">

- **TLB miss** → **페이지 번호가 TLB에 없는 경우**
    - 주소 변환은 기본 방법으로 진행되고, 페이지 테이블에 대한 메모리 참조가 이루어져야 한다.
    - 프레임 번호가 확보되면, 이를 사용해서 메모리에 액세스할 수 있다.

</br>

- 만약 TLB가 가득 차면, 기존 항목 중에서 교체될 항목을 선택해야 한다.
    - 교체 정책은 LRU, 라운드 로빈, 무작위 등 다양한 정책이 사용된다.

</br>

> **어떤 TLB는 각 항목에 ASIDs(address-space identifiers)를 저장하기도 한다.**

→ **ASID는 그 TLB 항목이 어느 프로세스에 속한 것인지를 알려주며, 그 프로세스의 정보를 보호하기 위해 사용된다.**

- **ASID가 맞지 않으면 TLB miss로 처리한다.**
    - ASID 지원이 있으면 한 TLB 안에 여러 프로세스의 정보를 동시에 함께 보관할 수 있다.
    - ASID 지원이 없으면, 새로운 페이지 테이블이 선택될 때마다 TLB는 전부 **플러시(flush)**되어야 한다.

</br>

> **접근하려는 메모리의 페이지 번호가 TLB에서 발견되는 비율을 적중률(hit ratio)이라고 한다.**

- ex) 80% 적중률 = TLB에서 원하는 페이지 번호를 발견한 횟수가 80% 확률

</br>

> **실질 메모리 접근 시간(effective memory access time)**

→ `EAT = 2 + 메인 메모리 접근 시간 - 적중률`

</br>

### 보호

→ ***페이징 환경에서 메모리 보호는 각 페이지에 붙어있는 보호 비트(protection bits)에 의해 구현된다.***

- 이 비트들은 보통 페이지 테이블에 속해 있다.

</br>

> **각 비트는 이 페이지가 읽고, 쓰기 또는 읽기 전용임을 각각 정의할 수 있다.**

- 메모리에 대한 모든 접근은 페이지 테이블을 거치므로, 주소 변환과 함께 이 페이지에 쓰기가 허용되는지 안 되는지에 대한 검사도 할 수 있다.
    - 읽기 전용 페이지에 관해 쓰기를 시도하면 운영체제가 하드웨어로 트랩(trap)을 걸어준다.

</br>

> **페이지 테이블의 각 엔트리에는 유효/무효(valid/invalid)라는 하나의 비트가 더 존재한다.**

<img width="394" alt="image" src="https://user-images.githubusercontent.com/106216912/221350873-545df919-798c-491b-9677-c3318dd2b32a.png">

- **유효** : 관련된 페이지가 **프로세스의 합법적인 페이지임**을 나타냄
- **무효** : 그 페이지는 **프로세스의 논리 주소 공간에 속하지 않는다는 것**을 나타냄

</br>

→ **운영체제는 이 비트를 사용해서 그 페이지에 대한 접근을 허용하든지, 또는 허용하지 않든지 할 수 있다!**

</br>

### 공유 페이지

→ ***페이징의 장점은 공통의 코드를 공유할 수 있다는 점이다.***

<img width="389" alt="image" src="https://user-images.githubusercontent.com/106216912/221350909-951ecf9d-cd64-4ce7-9f80-0cd61273955f.png">

- 코드가 **재진입 코드**인 경우, 위의 그림과 같이 공유할 수 있다.
    - 표준 C 라이브러리 `libc` 에 대한 페이지를 공유하는 세 가지 프로세스가 있다.
        - 재진입 코드는 자체 수정을 할 수 없는 코드로써, 실행 중에는 절대 변경되지 않는다.
        - 따라서, **두 개 이상의 프로세스가 동일한 코드를 동시에 실행**할 수 있다.
        - **하나의 사본만 저장하면 되고, 각 사용자 프로세스의 페이지 테이블은 동일한 물리적 사본으로 매핑**시킨다.

---

## 4. 페이지 테이블의 구조

### 계층적 페이징

→ ***현대 컴퓨터는 매우 큰 주소 공간을 갖고, 이러한 환경에서는 페이지 테이블도 상당히 커진다.***

- 이러한 경우, **페이지 테이블을 여러 개의 작은 조각으로 나누는 방법**이 존재한다.

</br>

> **한 가지 방법은 2단계 페이징으로써 페이지 테이블 자체가 다시 페이징되게 하는 것이다.**

<img width="391" alt="image" src="https://user-images.githubusercontent.com/106216912/221358471-891f8031-e619-437f-a963-3ef98feb5c5d.png">

- `p1` = 바깥 페이지 테이블의 인덱스, `p2` = 안쪽 페이지 테이블의 페이지 내의 오프셋
    - 주소 변환이 바깥 페이지 테이블에서 시작해서 안쪽으로 들어오므로, 이 방식을 forward-mapped 페이지 테이블이라고도 부른다.

</br>

> **하지만, 64비트 논리 주소 공간을 가진 시스템에서는 2단계 페이징 기법도 적절하지 못하다.**

- 이 경우, 바깥 페이지 테이블을 페이지시킴으로써 **3단계 페이지 방법**으로 만들 수 있다.
    - 그 후, 2번째 바깥 테이블 자체를 페이징하는 등 **4단계 페이징 기법**도 사용할 수 있다.

<img width="443" alt="image" src="https://user-images.githubusercontent.com/106216912/221358512-af40eac9-f124-4dd6-8d35-00a4873b03fb.png">

</br>

### 해시 페이지 테이블

→ ***주소 공간이 32비트보다 커지면, 가상 주소를 해시로 사용하는 해시 페이지 테이블을 많이 쓴다.***

- 해시 페이지 테이블의 각 항목은 연결 리스트를 가지고 있다.
    - 이곳에는 충돌을 일으켜서 모두 이곳으로 해시되는 원소들이 매달리게 된다.
    - 각 원소는 세 개의 필드를 갖는다.
        - **가상 페이지 번호**
        - **사상되는 페이지 프레임 번호**
        - **연결 리스트상의 다음 원소 포인터**

</br>

<img width="487" alt="image" src="https://user-images.githubusercontent.com/106216912/221358546-02d1f5ce-e594-4642-906a-d89eb8b15475.png">

- 알고리즘은 다음과 같이 작동된다.
    1. 가상 주소 공간으로부터 페이지 번호가 오면 그것을 해싱한다.
    2. 그것으로 해시 페이지 테이블에서 연결 리스트를 따라가며 첫 번째 원소와 가상 페이지 번호를 비교해본다.
    3. 일치하면 그에 대응하는 페이지 프레임 번호를 가져와 물리 주소를 얻는다.
    4. 일치되지 않으면 연결 리스트의 그 다음 원소로 똑같은 일을 반복한다.

</br>

> **64비트 시스템에서 유용하도록 변형된 해시 테이블 기법이 제안되었다.**

- 이 변형 기법은 해시 테이블과 비슷한 **클러스터 페이지 테이블**을 사용한다.
    - 해시 페이지 테이블 : 각 항목이 한 개의 페이지만 가리킨다.
    - 클러스터 페이지 테이블 : 각 항목은 여러 페이지를 가리킨다.

</br>

→ 클러스터 페이지 테이블은 **성긴 주소 공간**에 유용하게 사용된다.

</br>

### 역 페이지 테이블

→ ***일반적인 방법의 페이지 테이블의 단점은, 각 페이지 테이블 항목의 개수가 수백만 개가 될 수 있다는 것이다.***

- 이러한 **테이블은 물리 메모리의 사용을 추적하기 위해 많은 양의 물리 메모리를 소비**한다.

</br>

> **이 문제를 해결하는 방법이 역 페이지 테이블(inverted page table)이다.**

<img width="431" alt="image" src="https://user-images.githubusercontent.com/106216912/221358576-4772a18f-9464-4594-a18a-7636b243f85b.png">

- 역 페이지 테이블에서는 메모리 프레임마다 한 항목씩을 할당한다.
    - 각 항목은 그 프레임에 올라와 있는 페이지 주소, 그리고 그 페이지를 소유하고 있는 프로세스의 ID를 표시하고 있다.
    - 이렇게 되면 시스템에는 단 하나의 페이지 테이블만이 존재하게 되고, 테이블 내 각 항목은 메모리 한 프레임씩을 가리키게 된다.

</br>

> **이 방법은 논리 페이지마다 항목을 가지는 대신, 물리 프레임에 대응되는 항목만 테이블에 저장한다.**

→ **따라서, 메모리에서 훨씬 작은 공간을 점유한다.**

- 하지만, 역 페이지 테이블은 **주소 변환 시간이 더 오래 걸릴 수 있다.**
    - **역 페이지 테이블은 물리 주소에 따라 정렬되어 있고, 탐색은 가상 주소를 기준으로 하므로** 테이블 전체를 탐색해야 할 수도 있다.
        - 이 문제를 해결하기 위해 해시 테이블을 사용한다.

---

## 5. 스와핑

→ ***프로세스는 실행 중에 임시로 백업 저장장치로 내보내어 졌다가, 실행을 계속하기 위해 다시 메모리로 되돌아 올 수 있다.***

<img width="438" alt="image" src="https://user-images.githubusercontent.com/106216912/221359136-a8ed31b4-4961-4d60-85ea-d6e5d4276c48.png">

- 모든 프로세스의 물리 주소 공간 크기의 총합이 시스템의 실제 물리 메모리 크기보다 큰 경우에도 스와핑을 이용하면 동시에 실행하는 것이 가능하다.
    - **다중 프로그래밍의 정도**를 증가시킨다.

</br>

### 기본 스와핑

→ ***표준 스와핑에는 메인 메모리와 백업 저장장치 간에 전체 프로세스를 이동한다.***

- 백업 저장장치는 일반적으로 빠른 **보조저장장치**이다.
    - 백업 저장장치는 저장 및 다시 접근해야 하는 프로세스의 크기에 상관없이 수용할 수 있을 만큼 커야 하며, 이러한 메모리 이미지에 직접 액세스 할 수 있어야 한다.

</br>

> **표준 스와핑의 장점**

→ ***실제 물리 메모리보다 더 많은 프로세스를 수용할 수 있도록 물리 메모리가 초과 할당될 수 있다는 것이다.***

- **유휴, 또는 대부분의 시간을 유휴 상태로 보내는 프로세스**가 스와핑에 적합한 후보이다.
    - 이러한 비활성 프로세스에 할당된 모든 메모리는 활성 프로세스에 할당될 수 있다.
    - 스왑된 비활성 프로세스가 다시 활성화되려면 다시 스왑인 해야 한다.

</br>

### 페이징에서의 스와핑

→ ***대부분의 시스템은 이제 프로세스 전체가 아닌 프로세스 페이지를 스왑할 수 있는 변형 스와핑을 사용한다.***

- 이 전략은 여전히 물리 메모리를 초과 할당할 수 있지만, 프로세스 전체를 스왑하는 비용은 발생하지 않는다.
    - 단지 적은 수의 페이지만 스왑에 관여하기 때문이다.
    - 스와핑 : 표준 스와핑
    - 페이징 : 페이징에서의 스와핑

</br>

> **페이지-아웃  연산은 페이지를 메모리에서 백업 저장장치로 이동시킨다.**

- 반대 방향의 연산 : **페이지-인**

<img width="388" alt="image" src="https://user-images.githubusercontent.com/106216912/221359177-d8702e65-bdb5-416e-bb0a-080f2d0fc1c6.png">

</br>

### 모바일 시스템에서의 스와핑

→ ***모바일 시스템은 어떠한 형태의 스와핑도 지원하지 않는 것이 일반적이다.***

- 일반적으로 모바일 장치들은 비휘발성 저장장치로 공간을 많이 차지하는 하드디스크보다, 플래시 메모리를 사용한다.
    - 이 결과, 저장 공간이 줄어드는 것이 모바일 운영체제의 설계자가 스와핑을 피하게 되는 이유 중의 하나이다.

---